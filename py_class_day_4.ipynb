{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced32f0c",
   "metadata": {},
   "source": [
    "Working With Databases\n",
    "======================\n",
    "\n",
    "Python works and plays well with many of the most popular relational\n",
    "databases including PostgreSQL, Oracle and MySQL. The standard library\n",
    "even has a light-weight product, SQLite, capable of either running in\n",
    "memory or using the file system for persistent storage.\n",
    "\n",
    "For this chapter, we’ll work with Python’s **sqlite3** module. It\n",
    "requires no setup, definition of an administrator, or anything else – it\n",
    "comes “batteries included”. Also, since it’s part of standard Python you\n",
    "can rely on it working on any system with Python installed. If you later\n",
    "choose to use another database – no worries. You’ll need to find and\n",
    "install a piece of middleware called a “connector” and, of course, the\n",
    "database software. What you learn here will most apply to the\n",
    "alternative tools. and your interactions with the objects it provides\n",
    "will be nearly-identical those you have with **SQLite**. Switching\n",
    "should be easy.\n",
    "\n",
    "For the record, here are some popular connectors (which you may\n",
    "have to install using a package manager if they’re not in your Python\n",
    "installation).\n",
    "\n",
    "    MySQL: import mysql.connector\n",
    "    Oracle: import cx\\_Oracle\n",
    "    PostgreSQL: import psycog3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a0ed1",
   "metadata": {},
   "source": [
    "Basics\n",
    "------\n",
    "\n",
    "Let’s get started with importing **sqlite3** and connecting to a\n",
    "database. If we want to store it on the file system we provide the name\n",
    "of the file; if we just want it in memory, we can use the special name\n",
    "“:**memory**”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbf5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('mydb')\n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca1b893",
   "metadata": {},
   "source": [
    "The **connect** object is our gateway into the database. We can access\n",
    "its methods to change users, commit/roll back changes etc. and otherwise\n",
    "perform high-level operations at the database level. \n",
    "\n",
    "we’ll get a **cursor** object from the **connection** object which we’ll\n",
    "use for most of our interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "curs = conn.cursor()\n",
    "curs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586fe442",
   "metadata": {},
   "source": [
    "OK, we’ve got what we need to talk, so let’s have a conversation. The\n",
    "primary object in a database is a table. A table has rows and columns of\n",
    "information, and knows about relationships with other tables and their\n",
    "rows and columns. \n",
    "\n",
    "You can create a table using the CREATE keyword,\n",
    "something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"\"\"CREATE TABLE dogs (name CHAR(10),\n",
    "         toy CHAR(10),\n",
    "         weight INT(4))\n",
    "      \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dfeae0",
   "metadata": {},
   "source": [
    "Here, this command creates a table named ‘dogs.’ It has three columns:\n",
    "name, toy, and weight. We’ve assigned each column a data type. The\n",
    "numbers in (parentheses) indicate the size of the data. For instance\n",
    "‘name’ is specified to hold a maximum of 10 characters.\n",
    "\n",
    "**SQLite** supports other data types like TINYINT, BLOB, TEXT, and\n",
    "DOUBLE. You can read more about them in the sqlite.org docs.\n",
    "\n",
    "Data table names are unique – they have to be. So what happens if we try\n",
    "to create the table ‘dogs’ and one already exists? **SQLite** will whine\n",
    "miserably:\n",
    "\n",
    "    Traceback (most recent call last):\n",
    "    File \"stdin\", line 1, in module\n",
    "    sqlite3.OperationalError: table dogs already exist\n",
    "    \n",
    "So, it’s often a good idea to clear the decks first (if you’re sure you\n",
    "don’t need the table) by going:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8767ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"DROP TABLE IF EXISTS dogs\"\n",
    "curs.execute(cmd)  # this runs the SQL command\n",
    "\n",
    "# Create the table again, since we've killed the old one\n",
    "cmd = \"\"\"CREATE TABLE dogs (name CHAR(10),\n",
    "         toy CHAR(10),\n",
    "         weight INT(4))\n",
    "      \"\"\"\n",
    "curs.execute(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e30f3",
   "metadata": {},
   "source": [
    "When we’re done adding the new table, we can ask that the change be\n",
    "committed by using the connector method **commit**().\n",
    "\n",
    "    conn.commit() \n",
    "\n",
    "Now, let’s populate the kennel. The way to add a row is to use the\n",
    "INSERT command. The general syntax is:\n",
    "\n",
    "    INSERT INTO table ( column names) (values)\n",
    "\n",
    "Here’s an example. We’re telling the database that a 90-pound dog named\n",
    "Fang has a toy bone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59bf00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"INSERT INTO dogs ('name', 'toy', 'weight') VALUES (?, ?, ?)\"\n",
    "vals = ('Fang', 'bone', 90)\n",
    "curs.execute(cmd, vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34917902",
   "metadata": {},
   "source": [
    "Let’s make sure things are working by retrieving results. To do that you\n",
    "use the SELECT command. SELECT \\* asks for all rows. Generally the\n",
    "syntax is:\n",
    "\n",
    "    SELECT * FROM table WHERE some conditions\n",
    "\n",
    "If you don’t provide a WHERE clause, you get everything, as we do\n",
    "here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b0ea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"SELECT * from 'dogs'\"\n",
    "curs.execute(cmd)\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235d0c8",
   "metadata": {},
   "source": [
    "If the database finds rows matching your request, it passes that\n",
    "information to the cursor object. In order to actually extract data, you\n",
    "have to ask for it using one of the “fetch” methods which are:\n",
    "**fetchall**(), **fetchone**(), and **fetchmany**(). \n",
    "\n",
    "You need to provide **fetchmany** an integer to let it know how many rows you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43802acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = curs.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c3ac53",
   "metadata": {},
   "source": [
    "As you can see we get a **list** of **tuples**. If the query didn’t\n",
    "return anything, we’d get an empty **list**. \n",
    "\n",
    "We can now unpack the results using logic like:\n",
    "\n",
    "    column_1, column_2, column3 = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91267c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result:\n",
    "    print(\"Congrats, you've got you some dawgs!\")\n",
    "for row in result:\n",
    "    name, toy, weight = row\n",
    "    print(name, toy, weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c84aa2",
   "metadata": {},
   "source": [
    "Here’s an alternative way to add information using the **executemany**()\n",
    "method. Note that the first argument is the SQL command and the second\n",
    "is a **list**-like collection of **tuples** to be executed against it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf78948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curs.executemany('INSERT INTO dogs VALUES(?,?,?)',\n",
    "                     (('Biscuit', 'towel', '70'), \n",
    "                      ('Snoopy', 'squirrel', '60'),\n",
    "                      ('Sloopy', 'squirrel', '60'),\n",
    "                      ('Spooky', 'squirrel', '60'),\n",
    "                      ('Sparky', 'squirrel', '60'),\n",
    "                 )\n",
    "                 )\n",
    "conn.commit()\n",
    "\n",
    "cmd = \"SELECT * from 'dogs'\"\n",
    "curs.execute(cmd)\n",
    "result = curs.fetchall()\n",
    "for row in result:\n",
    "    name, toy, weight = row\n",
    "    print(name, toy, weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ac664",
   "metadata": {},
   "source": [
    "## Database Metadata\n",
    "\n",
    "We can see that printing these database tables is a tedious business with lots of repeated code.    Below, you'll find a quick-and-dirty routine that might expedite things.   \n",
    "\n",
    "To make printing a database table more generic, it would be nice to let it be agnostic about the names of the columns, wouldn't it?    We could hard-wire in the names of the columns that we want to print, but every time a column was added or removed we'd have more work to do.\n",
    "\n",
    "It's possible to query any database for its 'metadata' - that is data about itself.   Each product has a different way to store its own data, but it's easy enough to find out just how to do that.   You can, for instance, query for the names of the database tables, the names and data types of the columns within the tables, relationships between tables, and much more. \n",
    "\n",
    "It's also possible to query objects like the cursor to discover the characteristics of its payload.\n",
    "\n",
    "For instance, if we want to find out the names of the columns of data returned by a SELECT then we can query the description attribute of the cursor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed010d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"raw cursor description:\\n{curs.description}\\n\")\n",
    "\n",
    "# If we want a tuple of the column names:\n",
    "cols = tuple([element[0] for element in curs.description])\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cdc1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rows(tname):\n",
    "    \"A printing utility function you may want to keep\"\n",
    "    cmd = \"SELECT * from {}\".format(tname)\n",
    "    print(f\"Running command {cmd}\\n\")\n",
    "    curs.execute(cmd)\n",
    "    cols = tuple([element[0] for element in curs.description])\n",
    "    result = curs.fetchall()\n",
    "\n",
    "    if result:\n",
    "        for r in result:\n",
    "            nice_output = ''\n",
    "            for label, res in zip(cols, r):\n",
    "                nice_output += f\"{label:>10} = {res:<10} {'':<2}\"\n",
    "            print(nice_output)\n",
    "\n",
    "print_rows('dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc70f4c",
   "metadata": {},
   "source": [
    "If we want to know how many rows in the database table we can use\n",
    "COUNT(\\*).\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"SELECT COUNT(*) FROM {}\".format('dogs')\n",
    "curs.execute(cmd)\n",
    "\n",
    "# COUNT only returns one result.  Note the syntax for unpacking a one-element tuple\n",
    "result = curs.fetchone()\n",
    "number_of_rows, = result # result[0]\n",
    "\n",
    "print(\"Awesome, we've captured {} rows.\".format(number_of_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e4c03c",
   "metadata": {},
   "source": [
    "Lazy Evaluation\n",
    "---------------\n",
    "\n",
    "The cursor objects fetch methods are “lazily evaluated”. Like **range**\n",
    "objects and generators, they don’t actually produce information until\n",
    "requested to do so. This is an awesome feature because, even if your\n",
    "query returns a million rows, the cursor object has a minimal\n",
    "“footprint” in memory. \n",
    "\n",
    "You can, if you want, iterate through the entire\n",
    "thing a row at a time using the **fetchone**() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55331925",
   "metadata": {},
   "outputs": [],
   "source": [
    "curs.execute('SELECT * FROM dogs')\n",
    "while True:\n",
    "    row = curs.fetchone()\n",
    "    if not row:\n",
    "        break\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b42524",
   "metadata": {},
   "source": [
    "One of the implications of all this is that you can’t “rewind” the\n",
    "cursor – it’s only looking forward. And when they’re done, they’re done\n",
    "once you’ve run through the catch, if you want another look you’ve got\n",
    "to execute the query again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3866ebd5",
   "metadata": {},
   "source": [
    "Choosing Data with WHERE\n",
    "------------------------\n",
    "\n",
    "Often you don’t want all the data available, but only that which meets\n",
    "certain criteria. \n",
    "\n",
    "We can upgrade our SELECT directive to choose only\n",
    "certain rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a596810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'SELECT name, weight FROM dogs WHERE weight = 60'\n",
    "print(cmd)\n",
    "curs.execute(cmd)\n",
    "print(curs.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f6fee",
   "metadata": {},
   "source": [
    "If you would prefer that the data be sorted, you can use the ORDER BY\n",
    "directive.\n",
    "\n",
    "Note that you can make liberal use of whitespace in a SQL command to maintain your sanity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e087639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rows('dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = '''\n",
    "    SELECT\n",
    "        name, weight\n",
    "    FROM\n",
    "        dogs\n",
    "    WHERE\n",
    "        weight > 1\n",
    "    ORDER BY \n",
    "         weight, name\n",
    "    '''\n",
    "print(cmd)\n",
    "curs.execute(cmd)\n",
    "curs.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5ddd71",
   "metadata": {},
   "source": [
    "Updating and Deleting Data\n",
    "--------------------------\n",
    "\n",
    "To update fields in data already contained in the database, we can use\n",
    "the UPDATE keyword. The general syntax is:\n",
    "\n",
    "    UPDATE table SET column value WHERE condition\n",
    "\n",
    "So, if we wanted Snoopy to put on a bit of weight, we could go something\n",
    "like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1439d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"\"\"UPDATE \n",
    "            dogs \n",
    "         SET \n",
    "            weight=666 \n",
    "         WHERE \n",
    "            name='Snoopy'\n",
    "      \"\"\"\n",
    "\n",
    "curs.execute(cmd)\n",
    "print_rows('dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29651d0",
   "metadata": {},
   "source": [
    "We can selectively delete data rows using the DELETE command. Its basic\n",
    "syntax is:\n",
    "\n",
    "    DELETE FROM table WHERE condition\n",
    "\n",
    "These examples show how to winnow down our pack of dogs using variants\n",
    "of DELETE. \n",
    "\n",
    "In the first example we’ll delete all rows where the “toy”\n",
    "column has a specific value. \n",
    "\n",
    "Next we’ll use a wildcard to find values vaguely like the toy we’re looking for. \n",
    "\n",
    "Finally, we execute DELETE\n",
    "without any conditions to eliminate all the data, but leaving any\n",
    "metadata (column specifications, keys, relationships, etc.) intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebc8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything\n",
    "cmd = \"SELECT * FROM dogs\"\n",
    "curs.execute(cmd)\n",
    "print_rows('dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf3f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump dogs with socks\n",
    "cmd = \"DELETE FROM dogs WHERE toy = 'sock'\"\n",
    "curs.execute(cmd)\n",
    "print_rows('dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbca33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a wildcard to the select\n",
    "\n",
    "# %<some str>      <some_str>%\n",
    "cmd = \"DELETE FROM dogs WHERE toy LIKE '%el'\"\n",
    "curs.execute(cmd)\n",
    "print_rows('dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go nuclear with a general delete (metadata survives)\n",
    "cmd = \"DELETE FROM dogs\"\n",
    "curs.execute(cmd)\n",
    "print_rows('dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d1aebd",
   "metadata": {},
   "source": [
    "## Database Use In Context\n",
    "\n",
    "There’s much more to working with databases, naturally, but you now know the basics. And you can integrate them into your apps without having to leave the Python environment.\n",
    "\n",
    "You'll likely use direct database commands like these and a database like SQLite for on-the-fly, temporary storage of data your program needs to stash.  \n",
    "\n",
    "If you simply need to pile up a queue of things like web addresses to visit, you can use something like collections.dequeue.  If you want to send interprocess messaging, you can use tools like Celery, Python's xmlrpc library, or Python's asynchio library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1169df3",
   "metadata": {},
   "source": [
    "Object-Relational Mapping\n",
    "-------------------------\n",
    "\n",
    "If you get serious about working with databases, especially in the\n",
    "context of a web application, you might look into ORM tools.\n",
    "Generally, these create Python objects that serve as proxies for actual\n",
    "database components. They provide an abstraction layer than can keep you\n",
    "away from the raw SQL code and greatly simplify both your coding task\n",
    "and maintenance chores.\n",
    "\n",
    "To give you a flavor of what these beasts have to offer, here’s some\n",
    "example Django code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ddb4eb",
   "metadata": {},
   "source": [
    "    from django.db import models\n",
    "\n",
    "    class SnakeId(models.Model):\n",
    "        id = models.AutoField(unique=True, primary_key=True)\n",
    "        thumb = models.CharField(max_length=80, blank=True, null=True)\n",
    "        species = models.CharField(max_length=50, blank=True, null=True)\n",
    "        img_file = models.CharField(max_length=80, blank=True, null=True)\n",
    "        r = models.IntegerField(blank=True, null=True)\n",
    "        b = models.IntegerField(blank=True, null=True)\n",
    "        g = models.IntegerField(blank=True, null=True)\n",
    "\n",
    "        def __str__(self):\n",
    "            return \"snake_{}\".format(self.id)\n",
    "\n",
    "        class Meta:\n",
    "            managed = True\n",
    "            db_table = 'snake_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09724f",
   "metadata": {},
   "source": [
    "This code describes a database table, its columns, and some metadata.  Let's break it down:\n",
    "\n",
    "    class SnakeId(models.Model):\n",
    "    \n",
    "This creates a subclass of the models.Model class from Django.   A 'Model' is a database table.\n",
    "\n",
    "    thumb = models.CharField(max_length=80, blank=True, null=True)\n",
    "    \n",
    "Attributes of the Model class are database columns.   The column 'thumb' is an instance of Django's CharField object that stands in for whatever string field your database happens to use.   Under the hood, Django will figure out the exact syntax of the SQL required to communicate with your database.   The 'blank=' and 'null=' bits tell the database and downstream template systems about any restrictions on allowing empty fields.\n",
    "\n",
    "        class Meta:\n",
    "            managed = True\n",
    "            db_table = 'snake_id'\n",
    "            \n",
    "In an optional Meta class, you can specify whether Django will take complete control over your database.   If you choose, Django will set relationships among tables, add tables/columns, delete tables/columns, etc. to alter the fundamental structure of your database as your Python-based specifications change.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75021f5e",
   "metadata": {},
   "source": [
    "By using Python objects (and some magic provided by Django) we can do\n",
    "database queries, pass the query results to a Django HTML template, and\n",
    "render a complete web page. \n",
    "\n",
    "Here's an example:\n",
    "\n",
    "    from django.shortcuts import render\n",
    "    \n",
    "    from .models import SnakeInfo,SnakeColors\n",
    "    \n",
    "    def make_view(render)\n",
    "        snakes = SnakeInfo.objects.order_by('species', 'id')\n",
    "        \n",
    "        objs_to_render=[]\n",
    "        for s in snakes:\n",
    "            colors=SnakeColors.objects.filter(snake=s.id).\n",
    "            order_by('-pct')\n",
    "            objs_to_render.append(colors.all())\n",
    "            context={'snakes': objs_to_render}\n",
    "            \n",
    "    return render(request, 'snakes/index.html', context)\n",
    "    \n",
    "    \n",
    "Here's what's going on:\n",
    "\n",
    "    snakes = SnakeInfo.objects.order_by('species', 'id')\n",
    "    \n",
    "This executes a SELECT command against the **SnakeInfo** table, requesting all rows, and including an ORDER BY clause.    \n",
    "    for s in snakes:\n",
    "    \n",
    "The **for** loop iterates through the returned rows and creates a SELECT statement against a second snake-related table **SnakeColors**, this time using the **id** column as a primary key, and applying a SORT directive.\n",
    "\n",
    "    return render(request, 'snakes/index.html', context)\n",
    "    \n",
    "The **render** directive is sufficient to produce an intact web page using the specified template file and the database query result.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c98e131",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Please read the data from py_baseball_data.csv. Column names are in the first row. Dates represent no-hitters. Create a new database table and load this data.\n",
    "\n",
    "Write SQL statements that will let your code figure out how many no-hitters were pitch after June by NL teams.\n",
    "\n",
    "Write unittests to determine that your code works. \n",
    "\n",
    "Hint: you can execute the database creation code in setUp() and destroy the database in tearDown. Individual tests might INSERT or DELETE data and ensure your count stays correct.\n",
    "\n",
    "Solution: solution_database.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d15aff",
   "metadata": {},
   "source": [
    "***********************************************\n",
    "\n",
    "If you're just getting back ...\n",
    "\n",
    "... we're working on the exercise in Section 15.8\n",
    "    above.   I'll check in again at the top of the\n",
    "    hour.\n",
    "    \n",
    "- Pat\n",
    "\n",
    "\n",
    "\n",
    "************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e737211",
   "metadata": {},
   "source": [
    "Logging\n",
    "=======\n",
    "\n",
    "Python’s standard library comes with a comprehensive **logging** utility\n",
    "which is powerful yet easy to use. Logging allows you to get away from\n",
    "relying on **print**() statements to track the progress of your apps. It\n",
    "also allows you to selectively choose what to log, and to dynamically\n",
    "update your choice from within your script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5700faf6",
   "metadata": {},
   "source": [
    "Basics\n",
    "------\n",
    "\n",
    "The easiest way to get logging going is to use the logging module’s\n",
    "**basicConfig**() method. This tees up essential logging functionality\n",
    "and produces a **logging**.**logger** that you can access later. \n",
    "\n",
    "Let’s begin with a simple example (note - this may require a kernel restart):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881524dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "log_fn = os.path.join(os.getcwd(), \"py_log_output.log\")\n",
    "logging.basicConfig(filename=log_fn, level=logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "# this writes a line to the file\n",
    "logger.debug(\"Yup, I'm debugging\")\n",
    "print('logger on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded8871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bonus utility function\n",
    "def print_file(fn):\n",
    "    \"Reads and prints a text file\"\n",
    "    import os\n",
    "    if os.path.exists(fn):\n",
    "        with open(fn) as f:\n",
    "            for line in f:\n",
    "                print(line)\n",
    "    else:\n",
    "        print(f\"Sorry, file {fn} doesn't exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee5547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_file(log_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf3fa1",
   "metadata": {},
   "source": [
    "Logging Levels\n",
    "--------------\n",
    "\n",
    "The logger comes with five logging levels “baked in”. It’s possible to\n",
    "add custom levels, but these work for most situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "LOG_FILENAME = \"py_log_output.log\"\n",
    "LEVELS = {'debug': logging.DEBUG,\n",
    "          'info': logging.INFO,\n",
    "          'warning': logging.WARNING,\n",
    "          'error': logging.ERROR,\n",
    "          'critical': logging.CRITICAL\n",
    "          }\n",
    "logging.basicConfig(filename=LOG_FILENAME, level=LEVELS['debug'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d7e4a",
   "metadata": {},
   "source": [
    "When we set up the logger, we have gone ahead and set the logging level.  So what do we mean by “logging level”? \n",
    "\n",
    "Here’s a way to think about it. When we log an event, we do so with commands like:\n",
    "\n",
    "    logging.debug(“Some in-the-weeds-information”)\n",
    "    logging.critical(“Western Civilization As We Know It Is Ending!”)\n",
    "\n",
    "\n",
    "Unlike the familiar **print** function, these will not necessarily\n",
    "create a logging event every time the code is run. They will only fire\n",
    "if they are “worse” than the level we’ve assigned.\n",
    "\n",
    "Under the hood, the logger assigns “points” to each level:\n",
    "\n",
    "    logging.DEBUG=10\n",
    "    logging.INFO=20\n",
    "    logging.WARNING=30\n",
    "    logging.ERROR=40\n",
    "    logging.CRITICAL=50\n",
    "\n",
    "**logging**.**info**() creates a logging event worth 20 “points”. If the\n",
    "default level is set to a “point value” less than or equal to that\n",
    "(DEBUG or INFO) the log event fires.\n",
    "\n",
    "The idea is that you can sprinkle your code with messages at a variety\n",
    "of logging levels. During debugging, you might want really verbose\n",
    "output so you can monitor what’s going on. In production you might only\n",
    "want to know when the wheels are coming off. If you’re logging network\n",
    "traffic, you might want to differentiate between (potentially) benign\n",
    "anomalies and intrusion signatures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465eb00b",
   "metadata": {},
   "source": [
    "Dynamically Changing the Level\n",
    "------------------------------\n",
    "\n",
    "You can change the logging level dynamically by accessing the **logger**\n",
    "object. Here’s a short app to demonstrate how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa11f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shout_out():\n",
    "    # Cycle through the different built-in levels\n",
    "    logging.debug(\"shouting out at debug level\")\n",
    "    logging.info(\"shouting out at info level\")\n",
    "    logging.warning(\"shouting out at warning level\")\n",
    "    logging.error(\"shouting out at error level\")\n",
    "    logging.critical(\"shouting out at critical level\")\n",
    "    logging.debug(\"--------\")\n",
    "\n",
    "\n",
    "# log at all levels with level set to DEBUG\n",
    "shout_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e53c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "shout_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6937282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shout_out():\n",
    "    # Cycle through the different built-in levels\n",
    "    logging.debug(\"shouting out at debug level\")\n",
    "    logging.info(\"shouting out at info level\")\n",
    "    logging.warning(\"shouting out at warning level\")\n",
    "    logging.error(\"shouting out at error level\")\n",
    "    logging.critical(\"shouting out at critical level\")\n",
    "    logging.debug(\"--------\")\n",
    "\n",
    "\n",
    "# log at all levels with level set to DEBUG\n",
    "shout_out()\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "shout_out()\n",
    "\n",
    "# Reset to DEBUG\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "print_file(log_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb0971",
   "metadata": {},
   "source": [
    "Customizing Your Logging\n",
    "------------------------\n",
    "\n",
    "You’re not stuck with the default levels. Internally, the system knows\n",
    "the “point value” for all these, but you can assign your own.\n",
    "\n",
    "Let’s say that you have identified a situation that raises a\n",
    "WombatException. You might decide that its criticality is something\n",
    "between WARNING and ERROR and want to adjust accordingly. \n",
    "\n",
    "You can\n",
    "create a logging message by grabbing an instance of the logger and\n",
    "utilize its **getlogger**() method, something like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd8946",
   "metadata": {},
   "source": [
    "    class WombatException(Exception):\n",
    "        logger=logging.getLogger()\n",
    "        logger.log(WOMBAT, \"Wombat!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb154e0",
   "metadata": {},
   "source": [
    "You can also customize what your logging message looks like, borrowing\n",
    "system object like the name of the module, the name of the function, and\n",
    "time of day. You can do this as part of the **basicConfig**() setup by\n",
    "going something like:\n",
    "\n",
    "\n",
    "    logging.basicConfig(filename=LOG_FILENAME,\n",
    "    level=logging.DEBUG, format=LOG_FORMAT)\n",
    "\n",
    "The LOG\\_FORMAT is sort of like the format string that you’d feed to\n",
    "**str**.**format**(). The main difference is that you can tap into\n",
    "predefined “wildcard” characters that are associated with system-level\n",
    "information like the module name, time of day, function name, etc.\n",
    "\n",
    "A format string defined thusly:\n",
    "\n",
    "\n",
    "LOG_FORMAT = \"%(asctime)s called from %(module)s: %(lineno)d %(message)s\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "… will produce a message like this one:\n",
    "\n",
    "|                                                            |\n",
    "|------------------------------------------------------------|\n",
    "| 2016-10-04 08:31:55,113 called from py\\_log\\_3: 11 Wombat! |\n",
    "\n",
    "Here are some of the more commonly-used format string options:\n",
    "\n",
    "    %(asctime)s default: 2003-07-08 16:49:45\n",
    "    %(created)f time created\n",
    "    %(filename)s filename only\n",
    "    %(pathname)s full path\n",
    "    %(funcName)s function called from\n",
    "    %(levelname)s level (DEBUG, etc.)\n",
    "    %(levelno)s level (10, etc.)\n",
    "    %(lineno)d line number\n",
    "    %(module)s module name\n",
    "    %(message)s message\n",
    "    %(name)s logger name\n",
    "\n",
    "\n",
    "You can find a complete listing of them in the official docs at https://docs.python.org/3/library/logging.html#logrecord-attributes.\n",
    "\n",
    "Here’s how one might implement a logger with a custom level, which might\n",
    "be triggered in the event of a real Wombat emergency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b9c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Logging constants\n",
    "WOMBAT = logging.WARNING + 1\n",
    "LOG_FILENAME = \"py_log_output.log\"\n",
    "LOG_FORMAT = \"%(asctime)s called from %(module)s: %(lineno)d %(message)s\"\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(filename=LOG_FILENAME,\n",
    "                    level=logging.DEBUG,\n",
    "                    format=LOG_FORMAT)\n",
    "\n",
    "# Custom exception\n",
    "\n",
    "\n",
    "class WombatException(Exception):\n",
    "    logger = logging.getLogger()\n",
    "    logger.log(WOMBAT, \"Wombat!\")\n",
    "\n",
    "# Raise the alarm!\n",
    "\n",
    "\n",
    "def do_raise_wombat():\n",
    "    raise WombatException\n",
    "\n",
    "demo_mode = False\n",
    "if demo_mode:\n",
    "    raise_wombat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e06d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_file(log_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56290bd",
   "metadata": {},
   "source": [
    "Logging to Multiple Destinations\n",
    "--------------------------------\n",
    "\n",
    "You might find yourself needing to separate logging traffic into\n",
    "something like a “log of record” which records every bit of minutia.\n",
    "Maybe you’re cataloguing all the IP traffic on a site and hanging onto\n",
    "it for a week for potential forensic analysis. Vital stuff, but not\n",
    "intended for humans. You might want to have, in addition, a way to send\n",
    "only critical messages to human responders – maybe via a text message or\n",
    "phone call. Python’s **logging** library can handle that, too.\n",
    "\n",
    "**Logger** objects are endowed with “handlers” which manage the traffic\n",
    "from the logging system. Each logger can have multiple handlers, which\n",
    "can be configured separately. The default, which we’ve implicitly been\n",
    "using, is a **FileHandler**. As you’ve seen, it dutifully updates a\n",
    "designated log file with each event.\n",
    "\n",
    "Let’s say we want to send only critical messages to the console and log\n",
    "all messages in a file. \n",
    "Here’s how we might set up an extra handler for\n",
    "the critical messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290bf101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from docs/python.org/howto/logging-cookbook.html\n",
    "import logging\n",
    "\n",
    "LOG_FILENAME = \"py_log_output.log\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(name)-12s %(levelname)-8s’ ‘%(message)s',\n",
    "    datefmt='%m-%d %H:%M',\n",
    "    filename=LOG_FILENAME)\n",
    "\n",
    "# Create a new Handler\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.ERROR)\n",
    "\n",
    "# Create a new Formatter\n",
    "formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')\n",
    "\n",
    "# Install the Formatter in the Handler (just like tk widgets)\n",
    "console.setFormatter(formatter)\n",
    "\n",
    "# Install the Handler in the Logger\n",
    "logging.getLogger('').addHandler(console)\n",
    "\n",
    "# Let's try it out.\n",
    "logging.critical('Wombats have been detected!')\n",
    "logging.debug('just more boring log content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6371dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_file(LOG_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cdde0e",
   "metadata": {},
   "source": [
    "Another new wrinkle in this demo is the use of a time format. If the\n",
    "string “%(asctime)s” appears as part of the **logging**.**Formatter**\n",
    "specification, the system produces a **datetime** object. As such, you\n",
    "can use any of the normal **datetime** format strings with it.  Cf. https://strftime.org/\n",
    "Here, we’ve specified our choice with the “datefmt” keyword provided to\n",
    "**basicConfig.**\n",
    "\n",
    "Several “flavors” of handlers are available for different tasks. The\n",
    "**SocketHandler** will stream log output across a network (perhaps to a\n",
    "remote database). **SMTPHandler** can be used to send critical text\n",
    "message or email assuming, of course, you’ve got the capabilities set up\n",
    "already. The different “Rotating” handlers help manage large volumes of\n",
    "log traffic by archiving old files as necessary. \n",
    "\n",
    "The details are beyond\n",
    "the scope of this class, but here’s a list, for your reference.\n",
    "\n",
    "|                          |                   |\n",
    "|--------------------------|-------------------|\n",
    "| FileHandler              | SysLogHandler     |\n",
    "| StreamHandler            | DatagramHandler   |\n",
    "| NullHandler              | NTEventLogHandler |\n",
    "| WatchedFileHandler       | SMTPHandler       |\n",
    "| BaseRotatingHandler      | MemoryHandler     |\n",
    "| RotatingFileHandler      | HTTPHandler       |\n",
    "| TimedRotatingFileHandler | QueueHandler      |\n",
    "| SocketHandler            | QueueListener     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb41f8a0",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "The file py_log_english_brewery_data.csv is a text file containing all the breweries and their counties reported by Wikipedia. https://en.wikipedia.org/wiki/List_of_breweries_in_England\n",
    "Please create an app that:\n",
    "\n",
    "- De-duplicates the list\n",
    "\n",
    "\n",
    "- Identifies those with “Ale” in their name\n",
    "\n",
    "\n",
    "- Stores them in a database with (beer, is_ale, county) columns\n",
    "\n",
    "\n",
    "- Log the key events as your app steps through the process.\n",
    "\n",
    "Solution:  solution_logging.ipynb\n",
    "\n",
    "Extra credit:\n",
    "\n",
    "\n",
    "- Provides a simple GUI that lets users search the database for “Ale”/”non-Ale” breweries, and by county (they can type it in).\n",
    "\n",
    "Solution:  solution_logging_gui.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e7641",
   "metadata": {},
   "source": [
    "Introduction to NumPy\n",
    "======================================\n",
    "\n",
    "For real number-crunching Python offers the **numpy** library which\n",
    "includes all sorts of optimized array operations, and integrates well\n",
    "with other components of Python’s scientific stack\\[63\\].\n",
    "\n",
    "When working with **numpy**, you have to sacrifice some of the\n",
    "convenience of objects like **lists** and work with clearly-defined,\n",
    "single-type objects (as is the case when working with the **array**\n",
    "library). **numPy** is strongly typed – you have to declare everything\n",
    "as **float**, **int**, or some other C-type. It is not optimized for\n",
    "non-numeric types like strings.\n",
    "\n",
    "But if you’re serious about data, **numpy** is the right tool. It’s a\n",
    "very thin Python API (application program interface) written on top of\n",
    "compiled byte-code – which makes it blazing fast. It also has quite a\n",
    "bit of statistical and array manipulation capability baked right in, so\n",
    "is “one stop shopping” for most garden-variety projects (and some\n",
    "serious ones too).\n",
    "\n",
    "NumPy forms the basis of virtually every statistical application in the Python ecosystem.   For many applications, you'll never have to access it directly.  Pandas, for instance, has objects built directly onto numpy that are much easier to use.   But most objects use the ndarray as a base class, retaining all the characteristics of ndarrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae3b0b",
   "metadata": {},
   "source": [
    "## ndarrays\n",
    "\n",
    "The ndarray is the main object in the numpy library.  As the name applies, it can contain an arbitrary n-dimensional data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3c071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.array([1, 2, 3])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f73cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324483a2",
   "metadata": {},
   "source": [
    "## Constructors\n",
    "\n",
    "If you don't want to use one of the default instantiation methods, you\n",
    "can create a home-made array directly from a **list** of tuples. A\n",
    "**tuple** of lists, **tuple** of tuples, and **list** of lists also\n",
    "work. Here's how you might whistle up a 2-D array - as you can see, the\n",
    "**ndarray** object represents itself as an 'array', presenting its\n",
    "contents like a **list** of lists would."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed388143",
   "metadata": {},
   "source": [
    "Note:  If you know how big your array will be, it's best to use a constructor to create a placeholder, then fill it.\n",
    "\n",
    "Under the hood, memory will be allocated only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace60bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array([(0, 1, 2, 3), (10, 11, 12, 13), (20, 21, 22, 23)])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d77d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape: {d.shape}  Dimensions: {d.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c725f6",
   "metadata": {},
   "source": [
    "You can just provide the dimensions.  Note the content will be garbage values close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d = np.ndarray((2, 3))\n",
    "array_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape: {array_2d.shape}  Dimensions: {array_2d.ndim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea61ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b73237f",
   "metadata": {},
   "source": [
    "Alternatively, you can create arrays pre-populated with default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713086e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shape = (2, 3)\n",
    "\n",
    "print('ones')\n",
    "print(np.ones(shape))\n",
    "print()\n",
    "\n",
    "print('zeros')\n",
    "print(np.zeros((2, 3)))\n",
    "print()\n",
    "\n",
    "print('empty')\n",
    "print(np.empty(shape))\n",
    "print()\n",
    "\n",
    "print('default values')\n",
    "shape = (3, 3)\n",
    "default_val = 5.0\n",
    "dtype = 'int'\n",
    "print(np.full(shape, default_val, dtype=dtype))\n",
    "print()\n",
    "\n",
    "print(\"identity\")\n",
    "print(np.eye(3, dtype=np.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c514f0e",
   "metadata": {},
   "source": [
    "If you want random numbers you can use one of the methods from the **np.random** library.\n",
    "\n",
    "This produces a 3x2 matrix of random numbers between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ed8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d03b3d",
   "metadata": {},
   "source": [
    "As you can see, a **numpy** array is not an **array**.**array** object\n",
    "or anything we’ve seen before. It is its own dog. Let’s chat it up a\n",
    "bit. The shape here is a **tuple** with a single element showing us the\n",
    "number of elements in its first (and only) dimension. \n",
    "\n",
    "You can use\n",
    "indexing and slicing operations, just as you would a **list** object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee394ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shape is a tuple, one element for each dimension, showing elements in that dimension\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2b5116",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e924b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f413fa55",
   "metadata": {},
   "source": [
    "Let’s make it more interesting and add another dimension. \n",
    "\n",
    "Notice that we can define it with the same syntax we used to compose a **list** of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This constructor literally uses a list of lists.  There are others.\n",
    "\n",
    "arr2d = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]\n",
    "                  ])\n",
    "\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have two dimensions with three elements in each.\n",
    "arr2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca330358",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d[:   , 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "[complex(x, x+1) for x in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c62571a",
   "metadata": {},
   "source": [
    "Numpy can also create an array from any sort of iterable object.   Here, we'll use a list comprehension to whistle up some complex numbers to do the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa9c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fromiter([complex(x, x+1) for x in range(4)], dtype=complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1058bd",
   "metadata": {},
   "source": [
    "## NumPy File Operations\n",
    "\n",
    "NumPy arrays can be created directly from a file (another form of a constructor).  They can also be written to files.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c9976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ndarray containing only integers.\n",
    "dtype = np.dtype('int8, float, int')\n",
    "d = np.array([(6, 3, 8), (20, 1, 80), (4, 3, 34)], dtype=dtype)\n",
    "print(d)\n",
    "# Write it to the file system.\n",
    "fn = 'junk.npy'\n",
    "d.tofile(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d756765",
   "metadata": {},
   "source": [
    "Note that we specified the data type with a **np.dtype** object created\n",
    "on the first line. More on data types later, but for now just know that\n",
    "we have to clue NumPy in on what shape and element types we'll be\n",
    "passing back and forth to the file system. \n",
    "\n",
    "If we don't, the default\n",
    "behavior is to save the data in a flattened format that we'd have to\n",
    "reshape once imported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50101e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the file as an array\n",
    "new_d = np.fromfile(fn, dtype=dtype)\n",
    "new_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f620fc9",
   "metadata": {},
   "source": [
    "Here's how we can make sure nothing got lost in transit.  Note that the '==' operator works in an element-wise fashion, comparing each array element pairwise, and coming up with a True/False call for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d == new_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ecb7b",
   "metadata": {},
   "source": [
    "So to check whether every comparision is True (each element is the same) we need to use the ndarray's **all()** method.  Note the parentheses.\n",
    "\n",
    "Also note that there's also an **any** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (d == new_d).any()\n",
    "print(f\"Are they equal?  {result}\")\n",
    "\n",
    "print(f\"Are the same shape? {d.shape == new_d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd627c5",
   "metadata": {},
   "source": [
    "We could also save the array as a binary file (the default behavior is\n",
    "to use Python-specific pickles). Building on the previous array\n",
    "definition, and using the **save**() and **load**() methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542887b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(fn, d)\n",
    "del d  # just to prove it works\n",
    "d = np.load(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84734256",
   "metadata": {},
   "source": [
    "Data Types\n",
    "----------\n",
    "\n",
    "### Built-in Numeric Data Types \n",
    "\n",
    "NumPy provides a great selection of numeric data types ( **'dtypes'**)\n",
    "that work with **ndarrays**. These include signed and unsigned integers\n",
    "(**int** / **uint**), floating point (**float**) and complex\n",
    "(**complex**) numbers. Integers can be specified in widths ranging from\n",
    "8 to 64 bytes, floats from 16 to 64, and complex as either 64 or\n",
    "128. These are named **float14**, **uint8**, etc.\n",
    "\n",
    "NumPy arrays can contain all sorts of different types of data. The only\n",
    "rule is that an array can contain only one type – and this is so each\n",
    "element is constrained to be the same size for computational efficiency.\n",
    "The type can be any of the built-in **dtypes** e.g., **uint64** or\n",
    "**complex32**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4658eb1b",
   "metadata": {},
   "source": [
    "### Custom Data Types\n",
    "\n",
    "It's also possible to \"roll your own\" data structures – and they can be\n",
    "heterogenous in terms of the object types they contain. \n",
    "\n",
    "For instance,\n",
    "you can create a dtype consisting of a string, a complex number, a\n",
    "float, and an integer so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee393f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = '|S4, c8, float16, int32'\n",
    "data = (\"hello\", complex(1, 2), 4.3, 6)\n",
    "g = np.array(data, dtype=dtype)\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86679601",
   "metadata": {},
   "source": [
    "Also,\n",
    "you'll notice that the string 'hello' got truncated to 'hell' – that\n",
    "because it was pruned to fit the specification. You'll note that this\n",
    "happened silently.\n",
    "\n",
    "You need to be careful in this regard. If the extra wide string you\n",
    "store gets truncated it may not be a big deal. But if you try to store\n",
    "too large a number, what gets stored can be really strange. You may\n",
    "want to see what happens on your machine, but when I try to store the\n",
    "number 10,000,000,000 as a 32-byte integer, the number that actually\n",
    "gets stored is 1,410,065,408. \n",
    "\n",
    "Silently. Yikes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42becb7",
   "metadata": {},
   "source": [
    "### **Object** Data Type\n",
    "\n",
    "It's possible to get around this issue by getting a little vague about\n",
    "the dtype specification by using **object** as the type. You might think\n",
    "this violates the notion that all the elements in an **ndarray** have to\n",
    "be the same size. But it doesn't because internally the **ndarray** is\n",
    "storing a reference only, and the reference can point to just about\n",
    "anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf104e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.array([(\"hello\", 23), ('goodby', 45)], dtype='object, int32')\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ebf2b",
   "metadata": {},
   "source": [
    "If you look carefully at this last example, you'll see that the array\n",
    "can be specified fairly compactly. \n",
    "\n",
    "The data can be provided as a\n",
    "**list** of tuples and the **dtype** can be specified all in a single\n",
    "command. Also, the string representation of the dtype consists of a\n",
    "**tuple** for each object – 'f0' and 'f1' are internal field name labels\n",
    "and the 'O' and 'i4' stand in for 'object' and the 4-byte integer.\n",
    "\n",
    "Here's an important performance note: if you create an array of objects,\n",
    "you'll likely give up some of **NumPy's** blazing-fast performance. \n",
    "\n",
    "Why?\n",
    "Because you're creating list-like objects where the \"stride length\" –\n",
    "the amount of memory required for each element in the array – is no\n",
    "longer sufficient to extract the data. \n",
    "\n",
    "A second step is imposed – the\n",
    "pointer to the object only gets us to the starting point of the\n",
    "contents, and the amount of memory allocated to the object needs to be\n",
    "discovered before the actual contents can be accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0198d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array([(0, 1, 2, 3), (10, 11, 12, 13), (20, 21, 22, 23)])\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf97d1c",
   "metadata": {},
   "source": [
    "Slicing and Indexing\n",
    "--------------------\n",
    "\n",
    "The number of elements in the shape **tuple** lets us know that the\n",
    "array has a \"**rank**\" of 2 – that's the number of dimensions, and the\n",
    "same as the number of axes. Alternatively, we could ask about the\n",
    "dimensions directly by querying the **ndim** property. The output\n",
    "reveals that the first axis provides an **index** over 3 **elements;**\n",
    "and the second provides an index over 4 elements.\n",
    "\n",
    "We can address parts of the array by using slicing operations, just as\n",
    "we did with the 1-D array. The only difference is that you can (but\n",
    "don't need to) address each dimension (\"**axis**\") independently. Here's\n",
    "how you can get a specific row and a specific element. By providing a\n",
    "single argument, we address the first axis of the array (the \"row\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc8765",
   "metadata": {},
   "source": [
    "## A Note on Precision\n",
    "\n",
    "For all its charm, **NumPy** arrays, being dependent on the hardware's\n",
    "floating point operations and its implementation of the underlying C\n",
    "libraries, generally can't offer more than 64-bit precision. This being\n",
    "said, it is possible to create a **ndarray** of **object** type\n",
    "(elements serve as pointers only) and use objects like\n",
    "**fractions**.**Fraction** and **decimal**.**Decimal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daacc5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions.Fraction (1, 3) --> (2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = d[1]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c4629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "element = d[1][1]\n",
    "element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899292b5",
   "metadata": {},
   "source": [
    "Let's examine this exchange. We can see that the result is an object\n",
    "with a single axis. If we provide a double index, we can extract a\n",
    "single element. The single element is no longer an array, but is\n",
    "whatever **dtype** numpy chose as a default (it'll take a guess based on\n",
    "the type of objects passed in via the constructor).\n",
    "\n",
    "We can get a little fancier, if we want, and extract an element (of\n",
    "block of elements) with a more complex slice based on specifications\n",
    "against both axes. The only difference is that we need to provide two\n",
    "slices, separated by a comma. The second slice, naturally, operates on\n",
    "the second axis - the \"columns\". \n",
    "\n",
    "Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baf29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]\n",
    "                  ])\n",
    "\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = arr2d[:, 1]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df351de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_left_chunk = arr2d[:2, 0:3]\n",
    "top_left_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_corner = arr2d[-1, -1]\n",
    "bottom_corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ce207",
   "metadata": {},
   "outputs": [],
   "source": [
    "stg = \"wertqwer\"\n",
    "stg.upper().title().startswith(\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf5207e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skip_cols = arr2d[:, ::2]\n",
    "skip_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(skip_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d9577",
   "metadata": {},
   "source": [
    "There are a couple things to note with this exchange. First, the object\n",
    "returned (unless it's a single element) is always an **ndarray**.\n",
    "Second, the object returned as a column represents itself the same way\n",
    "as the object returned as a row – potentially a bit confusing at first.\n",
    "\n",
    "As with lists, these arrays also work and play well with **slice**\n",
    "objects. These can enhance the transparency and maintainability of your\n",
    "code because you can use them anywhere a slice specification is\n",
    "appropriate. For instance you could replace the top\\_left\\_chunk\n",
    "definition with the following and achieve the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5f47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_slice = slice(0, 2)\n",
    "col_slice = slice(0, 3)\n",
    "top_left_chunk = arr2d[row_slice, col_slice]\n",
    "top_left_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea01138",
   "metadata": {},
   "source": [
    "## Copies and Views\n",
    "\n",
    "There's another similarity between lists and **ndarrays** – if you use\n",
    "the \"=\" operator, you don't make a fresh copy of the array. You simply\n",
    "give a second name to the same object. \n",
    "\n",
    "To make a real, \"**deep copy**\" you can either use the **copy**() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee732949",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = d\n",
    "id(e) == id(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce2758e",
   "metadata": {},
   "source": [
    "This goes much further. Remember the \"top\\_left\\_chunk\" and \"col\" arrays\n",
    "we just created? They aren't new objects, either – instead they are\n",
    "still \"joined at the hip\" to the original array – technically they are\n",
    "\"**views**\" of the original. An operation on any of them is reflected in\n",
    "the original. \n",
    "\n",
    "Check this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Our array 'd' is:\\n\\n{d}\")\n",
    "\n",
    "col = d[:, 1]\n",
    "print(f\"\\nOur column 'col' is:\\n\\n{col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We can change our column:\\n\")\n",
    "col[1] = 777\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d7998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Our array 'd' is:\\n\\n{d}\")\n",
    "\n",
    "print(f\"\\nThe array 'e' is also changed:\\n\\n{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fca3f7",
   "metadata": {},
   "source": [
    "To avoid this, we can make a new object with a copy() operation.   That \"burns the bridge\" between the two objects.\n",
    "\n",
    "Here, we do the hard copy, then change 'd' back, and 'e' will keep its present value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = d.copy()\n",
    "col[1] = 11\n",
    "\n",
    "print(f\"Our array 'd' is:\\n\\n{d}\")\n",
    "print(f\"\\nThe array 'e' is intact:\\n\\n{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056fea0",
   "metadata": {},
   "source": [
    "Under the hood, the system has allocated a chunk of memory for the\n",
    "original object. \n",
    "\n",
    "That same memory can be shared by one or more other\n",
    "objects – that's the \"view\" idea. Because the memory is shared,\n",
    "operations on any object that references that memory changes the state\n",
    "of the memory for all other objects. \n",
    "\n",
    "It's something to watch out for,\n",
    "particularly if you're going to need to expand or shrink the array later\n",
    "on. By default some operations have built-in checks for multiple references, but they can throw some non-intuitive\n",
    "errors and can be overridden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a60454",
   "metadata": {},
   "source": [
    "Note that because we now have two dimensions, we need to separate the\n",
    "slicing operation on the first dimension from the operation on the\n",
    "second with a comma.\n",
    "\n",
    "       arr2d[<slice of first dimension>, <slice of second dimension>]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad77fda",
   "metadata": {},
   "source": [
    "We can extract a row by naming it in the first dimension and choosing everything in the second:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"original:\\n{arr2d}\\n\")\n",
    "\n",
    "second_row = arr2d[1, :]\n",
    "second_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b51bdc",
   "metadata": {},
   "source": [
    "We can extract a column in the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f53bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"original:\\n{arr2d}\\n\")\n",
    "\n",
    "second_col = arr2d[:, 1]\n",
    "second_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2004157",
   "metadata": {},
   "source": [
    "Working With NumPy Objects\n",
    "=========================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2363ac",
   "metadata": {},
   "source": [
    "## High-Dimensions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e9124b",
   "metadata": {},
   "source": [
    "### Thinking in high dimensions\n",
    "\n",
    "Numpy ndarrays are capable of handling an arbitrary number of dimensions.\n",
    "\n",
    "That does not mean people do so well.   3-D is OK for most people because that's the world we live in.   Add a 4th dimension - call it 'time' maybe - and most can handle it.   After that ... all bets are off.\n",
    "\n",
    "One way to think about high dimensions is in terms of a \"feature\n",
    "set\" – how many things describe the object. \n",
    "\n",
    "We could consider physical characteristics of an object to be features - each with its own dimension.\n",
    "\n",
    "For a coin we might consider denomination, date, condition, where\n",
    "produced, nationality, shape, exterior ridges, etc. \n",
    "\n",
    "All could be\n",
    "considered dimensions and represented as axes in an **ndarray** object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef75cf",
   "metadata": {},
   "source": [
    "### Coding In high dimensions\n",
    "\n",
    "All operations discussed here extend into high-dimension objects – some,\n",
    "like slicing, are just a bit more complicated to think through and\n",
    "implement. Here are a few examples that you can use for practice. The\n",
    "first bit builds a stack of 2-D arrays. The top values are 3.xx, mid\n",
    "values are 2.xx and bottom values are 1.xx – just to make it easy to\n",
    "\"eyeball\" the results. \n",
    "\n",
    "There's no need to study the code below\n",
    "extensively – its main purpose is to show how you can build a\n",
    "dimensionally-complex array from smaller ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b6160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_box():\n",
    "\n",
    "    # Make a multi-celled container (think Rubrik's cube) from three layers.\n",
    "    top = np.empty((3, 3))\n",
    "    mid = np.empty((3, 3))\n",
    "    btm = np.empty((3, 3))\n",
    "\n",
    "    # Fill the cells with numbers that \"label\" each layer\n",
    "    for arr, val in zip((top, mid, btm), (3, 2, 1)):\n",
    "        for row in range(arr.shape[0]):\n",
    "            for col in range(arr.shape[1]):\n",
    "                arr[row, col] = np.random.random() + val\n",
    "\n",
    "    box = np.array((top, mid, btm))\n",
    "\n",
    "    return box\n",
    "\n",
    "\n",
    "box = make_box()\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d0d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Middle layer\n",
    "box[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c018b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Middle layer, middle row\n",
    "box[1, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b98458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Middle layer, middle row, middle element\n",
    "box[1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae050162",
   "metadata": {},
   "source": [
    "## Element-wise Operations\n",
    "\n",
    "**Numpy** array math is really easy because the operators work\n",
    "“element-wise” i.e., on the entire array, all at once. \n",
    "\n",
    "Some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a103095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e21cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"original:\\n{arr2d}\\n\")\n",
    "\n",
    "arr2d * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB:  Operations create new objects.  The original is unchanged.  If you want to replace the original you need to #be explicit, something like this will work:\n",
    "#\n",
    "#   arr2d = arr2d * 2\n",
    "\n",
    "print(f\"original:\\n{arr2d}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bbd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"original:\\n{arr2d}\\n\")\n",
    "\n",
    "arr2d**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6133c9b",
   "metadata": {},
   "source": [
    "You can also do some operation to a slice of an array, then combine the\n",
    "results with the original. \n",
    "\n",
    "Here’s how you might double the values of a\n",
    "single row. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3305ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"original:\\n{arr2d}\\n\")\n",
    "\n",
    "arr2d[1, ] = arr2d[1, ] * 2  # double values of second row.\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"original:\\n{arr2d}\\n\")\n",
    "\n",
    "arr2d.T  # transposition (switch rows and cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b255b22f",
   "metadata": {},
   "source": [
    "Other operations like +, -, and / all  perform calculations element-wise over the entire data structure.\n",
    "\n",
    "NB:  The * operator does element-wise multiplication.  The ndarray.dot() method does real matrix multiplication when applied between matrices.   The ndarray.dot() method calculates the dot product when applied between vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e415e",
   "metadata": {},
   "source": [
    "## Basic Statistical Info\n",
    "\n",
    "You can also perform analysis on all the elements to gather statistics.\n",
    "Here’s how, you can get the minimum, maximum, and other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in methods\n",
    "\n",
    "print(f\"sum: {arr2d.sum()}\")\n",
    "print(f\"mean: {arr2d.mean()}\")\n",
    "print(f\"min: {arr2d.min()}\")\n",
    "print(f\"max: {arr2d.max()}\")\n",
    "print(f\"standard deviation: {arr2d.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5664d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowing from scipy to generate column-wise stats\n",
    "\n",
    "from scipy import stats\n",
    "st = stats.describe(arr2d)\n",
    "print(st)\n",
    "print(f\"\\nmin:  {st.minmax[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada0925",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d7e852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Borrowing from pandas to get nice stats (works best in 1 or 2d)\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(arr2d).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5748c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb01bc3e",
   "metadata": {},
   "source": [
    "## Data Masks\n",
    "\n",
    "\n",
    "Along the same lines, here’s how you might use vectors to create a\n",
    "“mask” to extract the diagonal elements:\n",
    "    \n",
    "     row_mask=np.array([0,1,2])\n",
    "     col_mask=np.array([0,1,2])\n",
    "     \n",
    "These vector-wise masks can be applied against the two dimensions thusly:\n",
    "\n",
    "     arr2d[row_mask, col_mask]\n",
    "     \n",
    "... so the first row_mask element and the first col_mask element (0,0) get paired up to select an element of arr2d.  Then (1,1) and (2,2) get paired up.   The result is extraction of the diagonal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f48a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"original:\\n{arr2d}\\n\")\n",
    "\n",
    "row_mask = np.array([0, 1, 2])\n",
    "col_mask = np.array([0, 1, 2])\n",
    "arr2d[row_mask, col_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a250091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can verify this against the built-in diagonal() method:\n",
    "arr2d.diagonal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc98dcb",
   "metadata": {},
   "source": [
    "You create what’s called a “Boolean index” – basically a logical\n",
    "operation run against each element of the array. \n",
    "\n",
    "For instance, if you\n",
    "wanted to get the even numbers, you could go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ecd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"original:\\n{arr2d}\\n\")\n",
    "\n",
    "bool_index = arr2d % 2 == 0\n",
    "bool_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb1f58d",
   "metadata": {},
   "source": [
    "You can now use the multiplication operator to “mask out” the odd\n",
    "numbers. You could do that in situ, “zeroing out” the odd numbers, or\n",
    "extract them into a new array using the mask as an index operator.\n",
    "\n",
    "Element-wise multiplication takes care of the whole thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001bf954",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"original:\\n{arr2d}\\n\")\n",
    "\n",
    "arr2d * bool_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03236818",
   "metadata": {},
   "source": [
    "Numpy also has several methods in the **numpy.ma** library to support\n",
    "these operations. A common use case is to \"weed out\" values that would\n",
    "otherwise goof up a calculation. \n",
    "\n",
    "Here's an example using the\n",
    "**masked\\_array**() method against an array containing a null **np.nan**\n",
    "value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan  #NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78844016",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.array([1, np.nan, 3])\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4880e",
   "metadata": {},
   "source": [
    "This is problematic because Numpy isn't clever enough to do a mean calculation with a null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf5f90c",
   "metadata": {},
   "source": [
    "One way to handle it is to get rid of the null value using **np.ma.masked_array()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1680258",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ma.masked_array(g, [False, True, False]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e12e84",
   "metadata": {},
   "source": [
    "Shape Shifting\n",
    "--------------\n",
    "\n",
    "NumPy supports methods to change the shape of an array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169fac26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = np.array([[1,   2,  3,  4],\n",
    "              [5,   6,  7,  8],\n",
    "              [9,  10, 11, 12],\n",
    "              ])\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9129b1",
   "metadata": {},
   "source": [
    "For instance if\n",
    "you want to \"vectorize\" an array i.e., make a 1-D object from higher\n",
    "dimension one, you can use the **ravel**() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb08f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = d.ravel()\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a862f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a71c5",
   "metadata": {},
   "source": [
    "If you want to make a version of a flattened array that you can iterate over, you can use **np.flatiter()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf85c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_version = d.flat\n",
    "iter_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b2d42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "next(iter_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ce431",
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ffac1d",
   "metadata": {},
   "source": [
    "The opposite operation can be accomplished with the **reshape**()\n",
    "method. The idea is that you can specify the shape of a new object by\n",
    "providing a **tuple**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d687cc",
   "metadata": {},
   "source": [
    "Of course, you don't need to restore the orginal shape.\n",
    "\n",
    "The only rule is that you need to account for\n",
    "each element in the original – in other words if the operation were\n",
    "Musical Chairs, everyone would get a seat when the song stops.\n",
    "Otherwise, you'll get a **ValueError**. \n",
    "\n",
    "For instance we could change the\n",
    "original object with shape (3, 4) to a new one with four rows by\n",
    "specifying a new shape (4, 3) like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34686ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.reshape(4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4c240c",
   "metadata": {},
   "source": [
    "It's possible to resize an array. For instance, we can use the\n",
    "**numpy.resize**() method to reduce the array we just created to a shape\n",
    "of (2,2). This will redistribute as many elements of the original that\n",
    "are required into the new object. \n",
    "\n",
    "This elements are chosen row-wise –\n",
    "taking the elements in the same order as provided with the **ravel**()\n",
    "method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.resize(e, (2, 2))\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47fdff7",
   "metadata": {},
   "source": [
    "We can also expand the size of the array. If we use **numpy.resize**()\n",
    "again to make it larger, the elements of the original array are\n",
    "distributed throughout the new array getting \"recycled\" as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ebb675",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.resize(e, (4, 4))\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f446b8",
   "metadata": {},
   "source": [
    "If we use the array method **resize**() – not the numpy method - the\n",
    "newly-created elements will default to zeros. \n",
    "\n",
    "This is an in place\n",
    "operation so there's no need to assign the result to a new object (in\n",
    "fact it returns **None**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4190b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.array([(1, 2, 3)])\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.resize((3, 3), refcheck=False)\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a994d",
   "metadata": {},
   "source": [
    "Note that we provided a keyword parameter via 'refcheck = False'.   Numpy is a bit of a 'nanny state' in this regard.  If we try to do something potentially dangerous to our data, it will issue a warning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3326e",
   "metadata": {},
   "source": [
    "## Scalar Products\n",
    "\n",
    "As seen earlier, scalar products can be obtained simply by using the * operator.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9403f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"original:\\n{arr2d}\\n\")\n",
    "\n",
    "arr2d * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6946173",
   "metadata": {},
   "source": [
    "Dot products (inherently between vectors) can be calculated with the dot() operator.  It's both a method of numpy and the ndarray.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5837918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = np.array([9, 10])\n",
    "vector2 = np.array([2, 3])\n",
    "\n",
    "print(f\"vector1: {vector1}\")\n",
    "print(f\"vector2: {vector2}\")\n",
    "\n",
    "np.dot(vector1, vector2)   # same as vector1.dot(vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f968a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0aa734",
   "metadata": {},
   "source": [
    "## Matrix Products\n",
    "\n",
    "Matrix products (inherently between matrices) can also be calculated with the dot operator.  \n",
    "\n",
    "In matrix mulitplication, we simply 'dot' the rows and columns.\n",
    "\n",
    "                     [ 13  9  7 ]        \n",
    "    [ 3 4 2]  np.dot [  8  7  4 ]   =  [ 3*13+4*8+2*6  3*9+4*7+2*4  3*7+4*4+2*0 ]  = [ 83  63  37 ]\n",
    "                     [  6  4  0 ]\n",
    "                     \n",
    "    [ 2 0 ]          [ 1 2 ]        =  [ 2*1+0*3    2*2_0*4 ] = [ 2 4 ]\n",
    "    [ 1 2 ]          [ 3 4 ]           [ 1*1+2*3    1*2+2*4 ]   [ 7 10]\n",
    "\n",
    "Check this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f5358",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_arr = np.array([3, 4, 2]).T   # transposition creates a column vector\n",
    "b_arr = np.array([[13, 9, 7], [8, 7, 4], [6, 4, 0]])\n",
    "\n",
    "print(f\"a_arr:  \\n{a_arr}\\n\")\n",
    "print(f\"b_arr:  \\n{b_arr}\")\n",
    "\n",
    "np.dot(a_arr, b_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_arr = np.array([[2, 0], [1, 2]])\n",
    "d_arr = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "print(f\"c_arr:  \\n{c_arr}\\n\")\n",
    "print(f\"d_arr:  \\n{d_arr}\")\n",
    "\n",
    "np.dot(c_arr, d_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5ab11",
   "metadata": {},
   "source": [
    "## Example:  Calculating Covariance\n",
    "\n",
    "Using Numpy's data manipulation tools, it's straightforward to calculate a covariance matrix.\n",
    "\n",
    "A covariance matrix provides the covariance between matched pair of elements. \n",
    "\n",
    "Covariance is a measure on how much closely high values of one variable correlate with high values of the other variable, and low values of one variable correlate with low variable of the other.   \n",
    "\n",
    "If high values of one variable go along with high values of the other and vice-versa, the covariance would approach 1.0.  If high values of one variable to with low values of the other, the covariance would approach -1.0.   If there's no relationship whatsoever, the covariance would be 0.\n",
    "\n",
    "More formally, covariance is the expected value (or mean) of the product of their deviations from their individual expected values.   For two variables X and Y:\n",
    "\n",
    "    covariance(X,Y) = E [  (X - E(X)) * (Y - E(Y)  ]\n",
    "\n",
    "The covariance of a variable with itself is the variance:\n",
    "\n",
    "    covariance(X,X) = E [ ( X - E(X)) ]\n",
    "    \n",
    "Variance is a measure of dispersion, or \"spread\" of a variable's distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce1e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate covariance between two arrays.\n",
    "\n",
    "# Setting a seed is optional, but if you provide a seed the random numbers are the same\n",
    "#    every time you run a script with random calculations.  Note that this ensures that\n",
    "#    the same sequence of random numbers will be generated from the time that the\n",
    "#    seed() method is called.   If you are just experimenting, you might want the same\n",
    "#    first number for each experiment.  In that case, you'll call seed() repeatedly.\n",
    "\n",
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Create vectors of values drawn from a normal distribution\n",
    "\n",
    "# Parameters of the normal distribution\n",
    "means_of_x_and_y = [10, 10]\n",
    "cov_of_x_and_y = np.array([[3, 1],      # var(X)   cov(X,Y)\n",
    "                           [1, 5]])     # cov(X,Y) var(Y)\n",
    "samples = 30\n",
    "\n",
    "# Create a matrix of values drawn from a normal distribution\n",
    "np.random.seed(1)\n",
    "x = np.random.multivariate_normal(means_of_x_and_y, cov_of_x_and_y, samples)\n",
    "\n",
    "\n",
    "# For each element, calculate difference between it and column mean.\n",
    "axis = 0  # Designates the 'column' axis\n",
    "u = x - x.mean(axis)\n",
    "\n",
    "# Calculate the sample covariance (N-1 instead of N in demoninator)\n",
    "cov = np.dot(u.T, u)/(samples-1)\n",
    "\n",
    "# Eyeball the result\n",
    "print(f\"Handmade covariance:\\n{cov}\\n\")\n",
    "\n",
    "# Check against Numpy's cov() function\n",
    "np_cov = np.cov(x.T)\n",
    "print(f\"Numpy covariance:\\n{np_cov}\\n\")\n",
    "\n",
    "# Check each element\n",
    "print(\"Element-wise check:\")\n",
    "truth_table = cov == np_cov\n",
    "print(truth_table)\n",
    "\n",
    "# Check the whole enchilada\n",
    "print(\"Checking for all True:\\n\")\n",
    "print(truth_table.all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea46b36",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## NumPy-specific Help\n",
    "\n",
    "Because Numpy is so complicated, it has several built-in ways to get help.\n",
    "\n",
    "    numpy.lookfor():   does a keyword search over docstrings.\n",
    "    numpy.info():      works like help() except one can provide a string to get multiple results\n",
    "    numpy.source():    returns the source code for any Python object (not the C code, though)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcf06d7",
   "metadata": {},
   "source": [
    "Numpy has built-in universal functions known as **ufuncs**.  Here's how to get help on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107720cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import doc\n",
    "help(doc.ufuncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(np.random.multivariate_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470a518e",
   "metadata": {},
   "source": [
    "A Real-World Application\n",
    "------------------------\n",
    "\n",
    "I have a special interest in Pythons. So much so that I’m trying to help\n",
    "get rid of Burmese Pythons and have designed a trap to do just that.\n",
    "With software written in Python, of course, and using **numpy** and\n",
    "Python’s image processing library **PIL**.\n",
    "\n",
    "Below, you’ll find some code to do chromatic reduction, pixel-wise on\n",
    "images of pythons within the trap.  How it actually works is beyond the scope of this course, but you may find it interesting.\n",
    "\n",
    "The take-away here is that much can be accomplished with a few lines of code by bouncing a digitized image back and forth between an image library and numpy's number-crunching abilities.\n",
    "\n",
    "To demonstrate, we'll assume we've caught a yellow-ish python in a black trap and snapped a glamour shot.   Our immediate goal is to remove the background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f783148",
   "metadata": {},
   "source": [
    "We begin by loading PIL (Python Image Lirary) and Numpy.   \n",
    "\n",
    "We'll open an image file and convert it to RGBA format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cadbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"a snake-charming application\"\"\"\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set up some handles to info we'll use later\n",
    "idir = os.getcwd()\n",
    "saveas = 'new_snake.PNG'\n",
    "image_name = './img_ds/media/snake_black.JPG'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c1f0ee",
   "metadata": {},
   "source": [
    "Here's the image in it's original JPG format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01326d8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_image = Image.open(image_name)\n",
    "raw_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9330c",
   "metadata": {},
   "source": [
    "The converted image doesn't look any different - it's just a different format that we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_image = raw_image.convert('RGBA')\n",
    "converted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82073ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Use PIL.Image to open the image and convert it to RGBA\n",
    "\n",
    "\n",
    "\n",
    "# Show the image in a modal window.\n",
    "raw_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b14613",
   "metadata": {},
   "source": [
    "There are several color models out there.  CMYK (cyan, magenta, yellow, black) is used for printing solid colors on media.  RGB and RGBA (red, green, blue, alpha) are used to create colors with light, as we do with computer monitors.  \n",
    "\n",
    "HSV (hue, saturation, value) and HSL (hue, saturation, lightness) allso used with solid colors and are useful in computer vision applications because proximate values appear to be close to the same color.\n",
    "\n",
    "Here we use the RGBA model because the channels are nicely discretized and map will into a data structure.   \n",
    "\n",
    "The RGBA version of our image is a 2-d array (width * height) or 4-element tuples.\n",
    "\n",
    "Here is how we might specify some colors and map them to the RGBA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some ndarrays to characterize colors\n",
    "white = np.array([255, 255, 255, 0])  # r, g, b, a\n",
    "black = np.array([0, 0, 0, 1])\n",
    "blue = np.array([0, 0, 255, 255])\n",
    "orange = np.array([255, 128, 0, 255])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fbd869",
   "metadata": {},
   "source": [
    "Now we can use the symmetry between the analytical, digitized version and the Image library's conversions to manipulate the image and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d90d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some image metadata\n",
    "\n",
    "converted_colors = converted_image.getcolors(w*h)\n",
    "\n",
    "# Dump the data into a numpy array and split the channels \"bands\"\n",
    "data = np.array(converted_image)  # h * w * 4 array (rgba)\n",
    "r, g, b, a = data.T\n",
    "\n",
    "background = black\n",
    "\n",
    "# Use masking condition and replaces the background color (& is boolean 'and')\n",
    "replace = (r == background[0]) & \\\n",
    "          (b == background[1]) & \\\n",
    "          (g == background[2])\n",
    "\n",
    "data[replace.T] = tuple(orange)\n",
    "\n",
    "# Generate a new image\n",
    "new_image = Image.fromarray(data, 'RGBA')\n",
    "\n",
    "new_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec3090",
   "metadata": {},
   "source": [
    "We can now tweak the image - perhaps the background isn't really black, but it's close:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 50\n",
    "\n",
    "data = np.array(converted_image)  # h * w * 4 array (rgba)\n",
    "r, g, b, a = data.T\n",
    "\n",
    "# Relax the criteria if needed (or even apply fuzzy logic)\n",
    "replace = (r <= THRESHOLD) &\\\n",
    "          (b <= THRESHOLD) &\\\n",
    "          (g <= THRESHOLD)\n",
    "\n",
    "data[replace.T] = tuple(orange)\n",
    "\n",
    "# Generate a new image\n",
    "new_image = Image.fromarray(data, 'RGBA')\n",
    "new_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122b3b7e",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "To celeberate completion of this class, you might have a party for your computer-oriented friends. \n",
    "\n",
    "Let's say you stock up with three 12-packs of great beer:\n",
    "\n",
    "Beer 1: IPA \n",
    "\n",
    "Beer 2: Lagar \n",
    "\n",
    "Beer 3: Stout \n",
    "\n",
    "Each 12-pack has three rows of bottles (call them 1, 2, and 3) and four \"columns\" of bottles (call them 1, 2, 3) as well.  You stack three racks of beer on top of each other in three layers.\n",
    "    \n",
    "    111 112 113 114    IPAs\n",
    "    121 122 123 124\n",
    "    131 132 133 134\n",
    "\n",
    "    211 212 213 214    Lagers\n",
    "    221 222 223 224\n",
    "    231 232 233 234\n",
    "\n",
    "    311 312 313 314    Stouts\n",
    "    321 322 323 324\n",
    "    331 332 333 334\n",
    "   \n",
    "Can you find a way to create a single numpy array looks just like this?    \n",
    "\n",
    "    Each array element will have a value of: (100 * beer value) + (10 * row value) + (1 * column value).\n",
    "\n",
    "Now, practice your slicing skills and see if you can strip out these chunks of the array: \n",
    "\n",
    "- only IPA\n",
    "\n",
    "\n",
    "- the middle two elements, of each of the bottom two rows of the Lagar portion: 222 223 232 233 \n",
    "\n",
    "\n",
    "- This middle row of the Stouts: 321 322 323 324 \n",
    "\n",
    "\n",
    "Solution:   solution_numpy_array_slicing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c118afe3",
   "metadata": {},
   "source": [
    "Overview of Data Visualization / Presentation Tools\n",
    "---------------------------------------------------\n",
    "\n",
    "### Introduction to Matplotlib and Seaborne\n",
    "\n",
    "Matplotlib is the visualization tool that's integrated into Numpy and\n",
    "pandas. It provides several \"out of the box\" plotting tools along with\n",
    "the ability to customize new charts and graphs through its API. Seaborne\n",
    "wraps Matplotlib and provides a suite of high-level, aggregate\n",
    "visualization tools. \n",
    "\n",
    "While this course is not focused on visualization,\n",
    "the current chapter will provide you enough background to spin up basic\n",
    "graphics and generally interact with the API.\n",
    "\n",
    "Enough to be dangerous,anyway ;-)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722ee03c",
   "metadata": {},
   "source": [
    "### Working With Matplotlib\n",
    "\n",
    "While working with Matplotlib can considerably more tedious than\n",
    "whistling up a chart with Excel or Open Office, the beauty is that it's\n",
    "tightly integrated with the other tools you'll be using. Over time,\n",
    "you'll build up an inventory of reusable objects/code to fit your needs\n",
    "to a tee.\n",
    "\n",
    "Fret not, however, because rudimentary graphics are ridiculously easy to\n",
    "produce. Here's a simple example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0b12f9",
   "metadata": {},
   "source": [
    " Overview of Pandas\n",
    "==================\n",
    "\n",
    "Pandas (the term is derived from \"panel\" and \"data”) is a data analysis\n",
    "framework developed by Wes McKinney in 2012 (he remains the\n",
    "BDFL). Built primarily on the NumPy **ndarray** object, it is\n",
    "particularly strong in handling date and time series because it provides\n",
    "high-level wrappers around Python's built-in **datetime** objects.\n",
    "Visualization based on Matplotlib is also knit into the main pandas\n",
    "objects. \n",
    "\n",
    "This chapter explores some of the more useful features of the\n",
    "pandas library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9915d2",
   "metadata": {},
   "source": [
    "Working With Pandas in an IDE\n",
    "-----------------------------\n",
    "\n",
    "The pandas library is fairly complex. It provides a variety of data\n",
    "structures and tools for manipulating sequences, two-dimensional tables,\n",
    "and three dimensional data panels. Due to its complexity, and that of\n",
    "the underlying **ndarray** objects, you may find an IDE valuable as you\n",
    "explore new objects and learn how to manipulate them.\n",
    "\n",
    "Over time, however, you may find that the GUI is more of a hindrance\n",
    "than an asset. There is quite a bit of overhead involved – not only to\n",
    "support the visual aspects, but in managing several threads/processes\n",
    "and having to push all the information through the sockets managed by\n",
    "the IDE software. As your data sets grow larger, performance will become\n",
    "a real issue. Besides, you'll likely be running your code on remote\n",
    "servers which won't be configured for GUIs.\n",
    "\n",
    "Fortunately, Python has several tools for text-only debugging in the\n",
    "standard library. \n",
    "\n",
    "For this course, we'll focus on examples written against the REPL or\n",
    "Jupyter notebooks for clarity of exposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fcc991",
   "metadata": {},
   "source": [
    "Enhancements from ndarray Objects\n",
    "---------------------------------\n",
    "\n",
    "The pandas library contains some really useful enhancements to NumPy\n",
    "arrays. \n",
    "\n",
    "### Indexing\n",
    "\n",
    "The principal advances are around indexing – pandas provides\n",
    "extremely flexible means of providing **datetime** and **str** indices\n",
    "on its objects while NumPy uses only integers.\n",
    "\n",
    "One of the implications is that the index objects have a separate\n",
    "existence from the objects they are associated with. It's possible, as\n",
    "we'll see later, to \"stretch\" an index value. For example, if we have\n",
    "weekly data originally using \"weeks\" as it's index we can reconstitute\n",
    "the index as \"days\" then reassign it. Before conducting operations on\n",
    "the array, its values will be aligned to the new index.\n",
    "\n",
    "### Missing Data\n",
    "Another important enhancement is that pandas objects handle missing data\n",
    "smoothly – much as SPSS or SAS does. This is important when dealing with\n",
    "\"stretched\" indices, for instance, when the now-unoccupied index points\n",
    "receive placeholder values. The nice thing is that the placeholders are\n",
    "evaluated just as you would hope when used for calculations. If you ask\n",
    "for the mean of a NumPy array with a single **numpy.NaN** value, the\n",
    "mean is reported as numpy.NaN. With pandas, the value simply drops out\n",
    "of the equation and the mean is reported as average of the remaining\n",
    "values.\n",
    "\n",
    "### Categorical Data\n",
    "\n",
    "Pandas also supports easy ways to \"bin\" values into buckets of\n",
    "user-definable ranges. This, in turn, allows creation of pivot tables\n",
    "and operations on categorized data. They also provide native support for\n",
    "database-like queries on data **Series** objects – no need to build an\n",
    "actual database or resort to \"roll your own\" means of selecting and\n",
    "organizing your information.\n",
    "\n",
    "### Object Compatibility\n",
    "\n",
    "Finally, since pandas are built on NumPy / SciPy, methods from these\n",
    "libraries can be applied to pandas data structures. Nothing has been\n",
    "left behind.\n",
    "\n",
    "Naturally, all of this comes at a performance cost relative to working\n",
    "with \"straight up\" **ndarrays**. A homogenous **ndarray** is\n",
    "computationally efficient and the tools used to manipulate it are thin\n",
    "wrappers around compiled C libraries. Wickedly fast. \n",
    "\n",
    "Pandas objects are\n",
    "a bit further away from the \"bare metal\" – in particular the requirement\n",
    "to consistently realign arrays to their indices requires a\n",
    "potentially-costly computational step every time the array is loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d884ef36",
   "metadata": {},
   "source": [
    "Series Objects\n",
    "--------------\n",
    "\n",
    "The **Series** object might be regarded as a chimeric combination of a\n",
    "**list**, a **dict**, and a database. It contains indexable elements,\n",
    "which can be looked up with keys, and selected / sorted as one might do\n",
    "with a database query.\n",
    "\n",
    "### Creating a Series\n",
    "\n",
    "Here's a simple way to create a **Series**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e50d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [10, 20, 30, 40]\n",
    "ser = pd.Series(data=data)\n",
    "\n",
    "ser\n",
    "type(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff499d29",
   "metadata": {},
   "source": [
    "To provide data, all we need to do is pass along an iterable object and\n",
    "**Series** takes over from there. As you can see, we get an index \"for\n",
    "free\" and the default is the same as for a **list** object – consecutive\n",
    "integers beginning with 0. **Series** even chose an appropriate data\n",
    "type (**int64**). Had we provided a **list** of **float** types the\n",
    "elements would be type **float64.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee11b3",
   "metadata": {},
   "source": [
    "### Addressing Elements\n",
    "\n",
    "We can work with it much as we would a **list**. For instance,\n",
    "**Series** objects support slicing. They also accept heterogeneous\n",
    "members. Note that as we add elements, the data type automatically\n",
    "adapts and now is **object**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7848ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser[0] = 'some string'\n",
    "ser[1] = (1, 2, 3)\n",
    "\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ab0fe",
   "metadata": {},
   "source": [
    "### Managing Elements\n",
    "\n",
    "Adding and removing elements works pretty much like operating on a\n",
    "**dict**. For instance, we can add a new element to a non-contiguous\n",
    "index point. We can simultaneously remove and capture a value using the\n",
    "**pop**() method. \n",
    "\n",
    "As is the case with a **dict**, the **get**() method\n",
    "is a little more robust because it accepts a default value to be\n",
    "returned in case the index doesn't exist (it's spared the trouble of\n",
    "producing a **KeyError**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f7001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_3 = ser.pop(3)\n",
    "value_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719bbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e73d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.get(666, 'nope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c1d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41da8f69",
   "metadata": {},
   "source": [
    "If you ever want to have a look at the index or the values, you can use\n",
    "methods by the same name to return **Series**-like objects. If you want\n",
    "to convert either to a **list**, you can use the **tolist**() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82282426",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ser.values.__repr__())\n",
    "\n",
    "ser.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f7e84c",
   "metadata": {},
   "source": [
    "### Searching\n",
    "\n",
    "We can also conduct searches on both the members' values and the\n",
    "**Series** index. To search for the presence of an index value,\n",
    "simply use the Python keyword **in**. \n",
    "\n",
    "To search values, we use\n",
    "the **isin()** method. \n",
    "\n",
    "The latter produces a \"Boolean mask\" – an object\n",
    "the same shape as the target, populated with **True** or **False**\n",
    "indicating presence or absence of the searched-for object in that\n",
    "location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b0990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 in ser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802d871a",
   "metadata": {},
   "source": [
    "666 in ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3023dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.isin([(1, 2, 3), 30, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5fe37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35307ab4",
   "metadata": {},
   "source": [
    "Note that the search terms can be arbitrarily numerous. The only rule is\n",
    "that they need to be provided as some **list**-like object – even if\n",
    "it's only one element. \n",
    "\n",
    "Both of these work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.isin([0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bdd13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.isin((1,))  # a one-element tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569e671a",
   "metadata": {},
   "source": [
    "To replace all the values in a **Series** with a new values, you can use\n",
    "the **replace**() method. For instance, if we had an instrument\n",
    "measuring absolute temperature (Kelvin), we can be pretty sure that zero\n",
    "is a bad reading. The instrument probably was off line. \n",
    "\n",
    "We can do an\n",
    "inplace substitution of the bad reading with a NaN like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a066496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "\n",
    "ser = pd.Series([100, 110, 0, 115])\n",
    "ser.replace(0, nan, inplace=True)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f242ec",
   "metadata": {},
   "source": [
    "### Managing Indices\n",
    "\n",
    "The **Series** object comes with a default index, as we've seen. It's\n",
    "possible to upgrade it by providing a new one. The only rules are that\n",
    "there has to be an index value for each element of the **Series**, and\n",
    "the value has to be immutable (just like a **dict**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83717de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [1,2,4]\n",
    "p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b6d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [10, 20, 30, 40]\n",
    "ser = pd.Series(data=data)\n",
    "ser.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f073f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.index = ('dog', 'cat', 'bear', 'anteater')\n",
    "ser.index"
   ]
  },
  {
   "cell_type": "raw",
   "id": "109a66af",
   "metadata": {},
   "source": [
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6367ff0f",
   "metadata": {},
   "source": [
    "We can now use the upgraded index to pick off individual elements.\n",
    "\n",
    "Alternatively, we can still get to them by using the index value if we\n",
    "provide it using the **iloc()** (\"index locator\") method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc10474",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e841e511",
   "metadata": {},
   "source": [
    "We'll do much more with the **Series** object as we explore\n",
    "**DataFrame**s in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc40e9",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Carbonify, an Australian nonprofit, maintains climate change information on its website: \n",
    "http://www.carbonify.com/carbon-dioxide-levels.htm.  Included is atmospheric CO2 saturation levels from the Mauna\n",
    "Loa Observatory in parts per million. Obeservations were taken in April of each year 1958-2017.\n",
    "\n",
    "\n",
    "The data is available to you as a list in 'mauna_loa_co2_starter_notebook.ipynb'.\n",
    "\n",
    "\n",
    "Please use your new knowledge to:\n",
    "\n",
    "- create a Series object from the list and apply an index to reflect the timeframe over which the data was collected;\n",
    "\n",
    "\n",
    "- replace any obviously bad values with a np.NaN object;\n",
    "\n",
    "\n",
    "- use the Series.mean() method and slicing operations to figure out the average CO2 saturations for the first 10 years and the last 10 years of data then print them out;\n",
    "\n",
    "\n",
    "- create a histogram of the cleaned-up data.\n",
    "\n",
    "Solution:  mauna_loa_co2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475477a8",
   "metadata": {},
   "source": [
    "Pandas in 2-D\n",
    "-------------\n",
    "\n",
    "**Series** object provide convenient containers for simple data like a\n",
    "company's stock's price over time. More often than not, we'll be\n",
    "interested in bundling several data streams, such as the stock prices of\n",
    "all companies in an industry. Further, we'll likely be interested in\n",
    "comparing contemporaneous prices and will be using using time as the\n",
    "common 'unit of analysis'. Pandas provides an object that's very\n",
    "well-suited to this task, the **DataFrame**.\n",
    "\n",
    "This section provides an overview of the **DataFrame** and its basic\n",
    "operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273be805",
   "metadata": {},
   "source": [
    "### The DataFrame\n",
    "\n",
    "The **DataFrame** object contains two dimensions of data. It's\n",
    "convenient to think of it as a spreadsheet or a database table. In fact,\n",
    "it has many of the characteristics of both. It's really a stack of\n",
    "**Series** objects (the ‘columns’). \n",
    "\n",
    "The stack can be indexed and\n",
    "addressed just as the **Series** objects are. \n",
    "\n",
    "Additionally, the\n",
    "**DataFrame** contains powerful methods for reading, writing, reshaping,\n",
    "combining, and otherwise manipulating data. Let's explore using a\n",
    "tangible example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100b1e9",
   "metadata": {},
   "source": [
    "### Creating an Instance\n",
    "\n",
    "One way to create a **DataFrame** is to provide an iterable object. In\n",
    "the example below, we'll use a **dict** object – this allows us to pass\n",
    "in index values for both \"rows\" and \"columns\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61cefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'c1': pd.Series([11, 21, 31], index=['r1', 'r2', 'r3']),\n",
    "        'c2': pd.Series([12, 22, 32], index=['r1', 'r2', 'r3']),\n",
    "        'c3': pd.Series([13, 23, 33], index=['r1', 'r2', 'r3']),\n",
    "        }\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5790815b",
   "metadata": {},
   "source": [
    "### Addressing Rows, Columns, and Elements\n",
    "\n",
    "By inspection, we can see that each **Series** object entered as a\n",
    "column in the 2-D table. If we want to extract a column, we can simply\n",
    "use its index value. To obtain an individual element, we can \"double\n",
    "index\" it, just as we can with an **ndarray**. \n",
    "\n",
    "There are a few ways to\n",
    "accomplish these tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a column\n",
    "df['c2']  # alternative: df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b121f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a row\n",
    "df.iloc[-1]  # alternative: df.loc['r3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a404b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single element\n",
    "df['c2']['r2']  # alternatives: df.at['r2', 'c2']); df.iat[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4880c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative methods\n",
    "df['c2']['r2'] == df.at['r2', 'c2'] == df.iat[1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4291239",
   "metadata": {},
   "source": [
    "### Scalar Operations\n",
    "\n",
    "**Series** and **DataFrame** objects support the same scalar\n",
    "(element-wise) operations as **ndarrays**. \n",
    "\n",
    "Here are a couple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47765f73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d62304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c1']*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2099c6",
   "metadata": {},
   "source": [
    "It's easy enough to add a column and apply a scalar operation using the\n",
    "**assign**() method. This code calculates a new column's values, assigns\n",
    "a new column index, and returns a 'scratch copy' of the original – all\n",
    "in one fell swoop. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee3017",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.assign(c4=df['c2']/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e92470",
   "metadata": {},
   "source": [
    "\n",
    "Note that the original is unchanged – we could simply\n",
    "reassign the name 'df' to the copy if we wanted to make the change\n",
    "permanent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71993ee",
   "metadata": {},
   "source": [
    "### Insertions and Deletions\n",
    "\n",
    "Observe that in the last example we didn't provide quotes around the\n",
    "name of the new column – that happens automatically \"under the hood\". If\n",
    "this isn't the desired behavior, you can insert a column \"manually\" with\n",
    "the same syntax as adding a **dict** entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c4'] = df['c2']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f60deb",
   "metadata": {},
   "source": [
    "To get rid of the new column we can use the system-level **del**\n",
    "command, just as with a **dict** object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['c4']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e123e",
   "metadata": {},
   "source": [
    "We can also insert columns using the **insert**() method. The general\n",
    "syntax is a bit different than that of **assign**():\n",
    "\n",
    "    df.insert ( insertion point (col number) , new index,  name , new data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da7ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can find the index value of a named column.\n",
    "col_index = df.columns.get_loc('c1')\n",
    "print(\n",
    "    f\"The DataFrame.columns.get_loc() method says col 'c1' is at index {col_index}.\\n\")\n",
    "\n",
    "# Here, we create and label a new Series.\n",
    "new_col = pd.Series(data=[666, 777, 888], index=('r1', 'r2', 'r3'))\n",
    "print(f\"Our new column is: \\n{new_col}.\\n\\n\")\n",
    "\n",
    "# Use the insert() method to inject a new column.\n",
    "df.insert(loc=col_index, column=\"new\", value=new_col)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12d08f",
   "metadata": {},
   "source": [
    "There are a few of things to note here.\n",
    "\n",
    "-   The col\\_index needs to be the integer value of the insertion point\n",
    "    – this can be retrieved with the **get\\_loc()** method of the\n",
    "    **columns** object.\n",
    "    \n",
    "\n",
    "-   **insert**() is an in-place operation. We didn't need to go: \"df =\n",
    "    df.insert...\" to make the changes permanent.\n",
    "    \n",
    "\n",
    "-   Since we provided row index values 'r1', 'r2', etc. earlier, we need\n",
    "    to include them here, as well. If we don't, the element values will\n",
    "    (silently) enter the **DataFrame** as **np.NaN**. \n",
    "    \n",
    "\n",
    "Here's an example\n",
    "    using a \"bad\" row index value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series with an index value 'xxx'\n",
    "new_col = pd.Series(data=[666, 777, 888], index=('r1', 'r2', 'xxx'))\n",
    "print(f\"Our new column is: \\n{new_col}.\\n\\n\")\n",
    "\n",
    "# Use DataFrame.insert() to poke in a new column.\n",
    "df.insert(loc=col_index, column=\"new1\", value=new_col)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ad628",
   "metadata": {},
   "source": [
    "If you want to add a row, a simple way to is to simply add a\n",
    "non-existing one using the **loc**() method. \n",
    "\n",
    "It has the effect of expanding the array and adding the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2272eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with some fresh data:\n",
    "\n",
    "data = {'c1': pd.Series([11, 21, 31], index=['r1', 'r2', 'r3']),\n",
    "        'c2': pd.Series([12, 22, 32], index=['r1', 'r2', 'r3']),\n",
    "        'c3': pd.Series([13, 23, 33], index=['r1', 'r2', 'r3']),\n",
    "        }\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our new row as a tuple.  Pandas will figure out what to do.\n",
    "row_data = (41, 42, 43)\n",
    "\n",
    "# Use the DataFrame.loc() method to add the row.\n",
    "df.loc['r4'] = row_data\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82a73ea",
   "metadata": {},
   "source": [
    "**Note:** that this isn't necessarily the most efficient way to expand an\n",
    "array. Much better if you can know *a priori* how big it will eventually\n",
    "be and can create a sufficiently-large empty one. Operations like this\n",
    "need to create new object, find memory for it, move existing content,\n",
    "then add the new data. All this can get expensive – especially for large\n",
    "data sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeb20c4",
   "metadata": {},
   "source": [
    "To delete a row, you can tap the **index** attribute. \n",
    "\n",
    "This example drops the last row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da05596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.index[-1])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c4e001",
   "metadata": {},
   "source": [
    "### Introspecting Indices\n",
    "\n",
    "If you ever need to discover the rows and columns, you can do so with\n",
    "the **index** and **columns** attributes. \n",
    "\n",
    "These will both produce an\n",
    "**Index** object (useful if you want to recycle the **index** for use in\n",
    "a new object – you can simply assign it to the new object's **index**\n",
    "attribute). \n",
    "\n",
    "Note that you can use \"cherry pick\" the rows returned by\n",
    "enumerating them. You can slice the columns for the same effect. \n",
    "\n",
    "If you\n",
    "want a straight up list, you can use the **tolist**() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf445da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df.iloc[[0, 2]].index.tolist()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d827d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3593e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns[0:2].tolist()\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef32d7",
   "metadata": {},
   "source": [
    "OK. You've now got a pretty good repertoire of skills working with\n",
    "**DataFrame** and **Series** objects. As you may have noticed these\n",
    "objects have a lot in common in terms of how to address elements and\n",
    "methods available to manipulate them. Please take a crack at the\n",
    "following exercises and test these skills out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aab16a",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "The Python machine learning library Scikit-Learn comes with several practice datasets. You can get to the Tenenhaus exercise and fitness database thusly:\n",
    "\n",
    "    >>> import sklearn.datasets as ds\n",
    "    >>> everything = ds.load_linnerud()\n",
    "\n",
    "The result, called 'everything' here, is a \"bunch class\". That's a class where all the objects are available via a dict-like object.\n",
    "\n",
    "    >>> everything.keys()\n",
    "    dict_keys(['target', 'data', 'DESCR', 'target_names', 'feature_names'])\n",
    "\n",
    "This object is a nice package of the description of the data sets and column names (data/feature_names and target/target_names). The data is already in ndarray format.\n",
    "\n",
    "    >>> type(everything['data'])    \n",
    "    class 'numpy.ndarray'\n",
    "    \n",
    "Most (if not all) of the practice datasets in the sklearn.datasets package are bundled in this fashion.\n",
    "\n",
    "\n",
    "Please work this data to:\n",
    "\n",
    "- Create a DataFrame for each of the target and data objects\n",
    "\n",
    "\n",
    "- Add the columns of the target DataFrame to the data DataFrame\n",
    "\n",
    "\n",
    "- The data database accounts for the situps, chinups, and jumping jacks each respondent performed. Add a new column to serve as an \"exercise index\": \n",
    "\n",
    "    3 * chinups + 2 * situps + jumping jacks.\n",
    "\n",
    "\n",
    "- The target database accounts for subjects' weight (lbs), waist (inches), and pulse (bpm). We'll want more civilized units for future analysis. Please convert the weight column to kg (2.2 lb = 1 kg) and waist column to cm (1 in = 2.54 cm).\n",
    "\n",
    "Solution:  solution_exercise.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac6181a",
   "metadata": {},
   "source": [
    "Pandas in 3-D\n",
    "-------------\n",
    "\n",
    "**Pandas** supports creating 3-D structures by stacking **DataFrame**\n",
    "objects – much as **DataFrame**s are essentially stacked **Series**\n",
    "objects. Individual **DataFrames** can be accessed by a third index\n",
    "variable. One way to conceptualize these 3-D objects is from their\n",
    "original intent – to serve as containers for panel data. You might have\n",
    "presidential approval survey data that displays answers (columns) by\n",
    "respondent (rows) that is collected each month so the \"**Panel**\" of\n",
    "respondents is tracked over time as the political winds blow. Time\n",
    "serves as the additional dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf74ebf",
   "metadata": {},
   "source": [
    " Data Acquisition\n",
    "================\n",
    "\n",
    "Numpy (and pandas) support tons of easy ways to create data structures\n",
    "directly or upon importing data from files, web pages, etc. They also\n",
    "support some powerful ways to examine, clean, and manipulate data once\n",
    "acquired. We'll discuss these here.\n",
    "\n",
    "The main methods are found in the ../pandas/io library and reading for\n",
    "text-like files is found in the module **parsers.py**. The latter is\n",
    "worth a quick look if you want to understand what's going on \"under the\n",
    "hood\" – important if you want to know about what the various arguments\n",
    "work, what the defaults are, how inferences about things like file types\n",
    "are managed, how duplicate columns are handled, etc. This chapter will\n",
    "discuss some of the more common data acquisition tools and introduce you\n",
    "to the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10a0ee6",
   "metadata": {},
   "source": [
    "### CSV Files\n",
    "\n",
    "CSV[19] is a common format for passing data files around because it's\n",
    "light-weight and (nearly) machine/application independent. Pandas'\n",
    "method to handle these, **read\\_csv()** extends the standard **csv**\n",
    "library by adding some additional parsing options and translators to\n",
    "create intact **DataFrame** and other objects.\n",
    "\n",
    "Let's get started by providing a small \\*.csv file and printing its\n",
    "contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bc9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'test_data.csv'\n",
    "\n",
    "with open(fn, 'w+') as f:\n",
    "    f.writelines([\"c1, c2, c3\\n\",\n",
    "                  \"11, 12, 13\\n\",\n",
    "                  \"21, 22, 23\\n\"]\n",
    "                 )\n",
    "    f.seek(0)\n",
    "\n",
    "    for line in f.readlines():\n",
    "        print(line[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2328ea18",
   "metadata": {},
   "source": [
    "Now, we can sic the **read\\_csv**() method on it thusly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(fn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0673d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We have a: {type(df)}\\n\")\n",
    "print(f\"With a shape:  {df.shape}\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f53c24e",
   "metadata": {},
   "source": [
    "You can see that this method has done a lot of heavy lifting. It handled\n",
    "the file open, close, and read operations. The first line was inferred\n",
    "to contain the column index values. The elements were correctly inferred\n",
    "to be integers. And it created a 2 row by 3 column **DataFrame** object\n",
    "with the appropriate indices and variable types without being asked. Not\n",
    "bad for one line of code!\n",
    "\n",
    "Naturally, we can override any of this default behavior. For instance,\n",
    "if we want to bring the data in as 16-byte floating point numbers, we\n",
    "could add the appropriate keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fn, dtype=np.float16)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67740f7e",
   "metadata": {},
   "source": [
    "The keyword overrides are extensive and (mostly) self-explanatory.\n",
    "Here's a list of them. The actual default values for things like **sep**\n",
    "(a comma) and the documentation for the rest of these can be found in\n",
    "the **TextParser**() method of **parsers.py**\n",
    "\n",
    "|                           |                          |                                 |\n",
    "|---------------------------|--------------------------|---------------------------------|\n",
    "| sep = sep                 | delimiter = None         | header = 'infer'                \n",
    "| names = None              | index\\_col = None        | usecols = None                  |\n",
    "| squeeze = False           | prefix = None            | mangle\\_dupe\\_cols = True       |\n",
    "| dtype = None              | engine = None            | converters = None               |\n",
    "| true\\_values = None       | false\\_values = None     | skipinitialspace = False        |\n",
    "| skiprows = None           | nrows = None             | na\\_values = None               |\n",
    "| keep\\_default\\_na = True  | na\\_filter = True        | verbose = False                 |\n",
    "| skip\\_blank\\_lines = True | parse\\_dates = False     | infer\\_datetime\\_format = False |\n",
    "| keep\\_date\\_col = False   | date\\_parser = None      | dayfirst = False                |\n",
    "| iterator = False          | chunksize = None         | compression = 'infer'           |\n",
    "| thousands = None          | decimal = b'.'           | lineterminator = None           |\n",
    "| quotechar = '\"'           | quoting = 0              | escapechar = None               |\n",
    "| comment = None            | encoding = None          | dialect = None                  |\n",
    "| tupleize\\_cols = False    | error\\_bad\\_lines = True | warn\\_bad\\_lines = True         |\n",
    "| skipfooter = 0            | skip\\_footer = 0         | doublequote = True              |\n",
    "| delim\\_whitespace = False | as\\_recarray = False     | compact\\_ints = False           |\n",
    "| use\\_unsigned = False     | low\\_memory = True       | buffer\\_lines = None            |\n",
    "| memory\\_map = False       | float\\_precision = None  |                                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c090cf",
   "metadata": {},
   "source": [
    "Some of the non-intuitive, but potentially useful, of these include:\n",
    "\n",
    "**date\\_parser** - you can include a function to handle this if your\n",
    "format is weird;\n",
    "\n",
    "**squeeze** – forces a **Series** instead of a **DataFrame** if there's\n",
    "only one column;\n",
    "\n",
    "**infer\\_datetime\\_format** – applies the first **datetime** string\n",
    "found to parse all others;\n",
    "\n",
    "**header** = None – overrides automatic grabbing first row as column\n",
    "headers;\n",
    "\n",
    "**usecols** – takes a **list** of the columns you want to pull into your\n",
    "new object.\n",
    "\n",
    "The **read\\_csv**() method can be used on many types of files – even\n",
    "compressed ones. It groks the compression method using the file name. So\n",
    "it's smart enough to know to run **gzip.GzipFile** against \\*.gzip\n",
    "files, **bz2** against \\*.bz2 files, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3086977d",
   "metadata": {},
   "source": [
    "### Spreadsheets\n",
    "\n",
    "Use the **pd.read\\_excel**() method to read spreadsheet-like files. This\n",
    "also works on URLs (local file:\\\\\\\\... or those served up over the\n",
    "Internet \"http:\\\\\\\\...\"). There are lots of options that you can specify\n",
    "with keyword arguments just like **read\\_csv**(). You can call\n",
    "**help**() to get a full listing. We'll discuss some of these here.\n",
    "\n",
    "**sheetname** - The default is 0, which grabs the first (zero-indexed)\n",
    "\"tab\" and returns a **DataFrame** object. Set it to some other integer\n",
    "to grab a different one. Specify **None** to return a **dict** with each\n",
    "\"tab\" in its own **DataFrame**. Alternatively, you can provide a name\n",
    "like \"Sheet1\". To get several \"tabs\" as a **dict** of **DataFrames**,\n",
    "specify a **list** of the ones you want. \\[2, 5, \"mySheet\"\\] will work\n",
    "just fine.\n",
    "\n",
    "**header** – The default is 0 meaning that the first row is the column\n",
    "header. You can override this to use a different row. Specify **None**\n",
    "if your data has no header row. Similarly, **index\\_col** is used to\n",
    "specify the column to be used as row labels.\n",
    "\n",
    "**parse\\_cols** – you can pick what columns to pull into your\n",
    "**DataFrame**. The default, **None**, grabs all the columns. You can\n",
    "specify a **list** of the column numbers (zero indexed) or a string. The\n",
    "string can contain individual columns or ranges – \"A, F, G:H\" will work.\n",
    "\n",
    "A couple of examples:\n",
    "\n",
    "    df = pd.read_excel(filename, usecols = \"A:M\")\n",
    "    df = pd.read_excel(filename, usecols = [1,3,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80320b",
   "metadata": {},
   "source": [
    "### Databases\n",
    "\n",
    "Pandas has several methods for reading database table contents, and even\n",
    "executing SQL queries, then transforming the \"take\" into a **DataFrame**\n",
    "object.\n",
    "\n",
    "The **read\\_sql\\_table**() method takes a table name and a connection\n",
    "object. The latter will be a live connection to a specific database,\n",
    "already authenticated with the user name, password, etc. as required.\n",
    "The connection object needs to be SQLAlchemy – the **sqlite** connector\n",
    "will not work.\n",
    "\n",
    "The **read\\_sql\\_query**() method is a little more flexible. You provide\n",
    "a SQL string containing your SELECT statement and a connection object.\n",
    "This method has maximum power when using a **SQLAlchemy** connector, but\n",
    "will work with a **sqlite** connector as well.\n",
    "\n",
    "**read\\_sql**() works pretty much like the other two methods – in fact\n",
    "it serves as a wrapper around both, selecting the appropriate one based\n",
    "on the connector type. The main difference is that if you use a\n",
    "**DBAPI2** connector object, it will ONLY read **sqlite** tables. If you\n",
    "use a **SQLAlchemy** connection, any other database is supported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2da8f",
   "metadata": {},
   "source": [
    "## BigQuery\n",
    "\n",
    "There is also an experimental method to execute commands against Google\n",
    "BigQuery[20] r**ead\\_bgq()**. This requires authentication into Google\n",
    "using OAuth 2.0 using the appropriate key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5fe5e0",
   "metadata": {},
   "source": [
    "## Data Chunking\n",
    "\n",
    "All these methods allow you to choose which columns to haul into your\n",
    "**DataFrame** object with the **columns** keyword (which works the same\n",
    "as the spreadsheet and csv methods). Additionally, they have a\n",
    "**parse\\_dates** option where you can provide a **list** or **dict** of\n",
    "columns to be parsed into **datetime** objects – this is valuable if the\n",
    "dates appear as strings in the target database. Finally, they have a\n",
    "**chunksize** option for use with really big databases. This creates an\n",
    "iterator that will pull in so many rows at a time so you don't bring\n",
    "your system to its knees by trying to take the whole database into\n",
    "memory at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a900da16",
   "metadata": {},
   "source": [
    "## HTML Tables\n",
    "\n",
    "You can, optionally, create pandas objects straight from a web site\n",
    "using **read\\_html**(). You feed it a URL-like string for an HTTP, FTP,\n",
    "or file URL page (not \"secure\" versions like HTTPS) and it will return a\n",
    "**list** of **DataFrame** objects, one for each table encountered. This,\n",
    "too, has lots of keyword options. See the docs and/or read\n",
    "..pandas/io/html/py for the gritty details.\n",
    "\n",
    "A few of the more useful keywords:\n",
    "\n",
    "> **match** – a regex used to figure out which tables to parse. The\n",
    "> default is \".+\" (grab everything), but that's probably not what you\n",
    "> want to do.\n",
    ">\n",
    "> **flavor** – this is the parsing engine to use. The default is\n",
    "> **lxml**. If that fails it uses **html5lib** (Beautiful Soup) as a\n",
    "> \"secondary default\".\n",
    ">\n",
    "> **attrs** – this is a **dict** to help identify the table you want to\n",
    "> use. The keys are valid HTML table attributes e.g., \"id\"\n",
    "\n",
    "Be aware that parsing web pages is a dicey business. While a parsing\n",
    "engine will do its level best, it can be thwarted by poorly-written HTML\n",
    "(missing tags, etc.), inconsistent use of id tags, strange encodings,\n",
    "etc. \"Trust, but verify\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe2a3f3",
   "metadata": {},
   "source": [
    "## Serialized Objects\n",
    "\n",
    "Pandas can produce **DataFrame** objects from a variety of serialized\n",
    "formats. Available methods include:\n",
    "\n",
    "**read\\_json**() – reads JSON files\n",
    "\n",
    "**read\\_msgpack**() – reads msgpack (sort of a \"JSON lite\" format) files\n",
    "\n",
    "**read\\_pickle**() – reads the Python-specific pickle format\n",
    "\n",
    "**read\\_hdf**() – reads HDF-5 files (efficient storage of homogenous\n",
    "data arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb0870",
   "metadata": {},
   "source": [
    "## Other Formats\n",
    "\n",
    "Pandas supports creation of **DataFrames** from a few other formats.\n",
    "These methods are similar to the others discussed so I'll just mention\n",
    "them here.\n",
    "\n",
    "**read\\_strata**() - for Strata (similar to SAS/SPSS) files\n",
    "\n",
    "**read\\_sas**() – reads XPORTed SAS files or those formatted as SAS7BDAT\n",
    "\n",
    "**read\\_table**() – use this for general delimited file, similar to\n",
    "read\\_csv()\n",
    "\n",
    "**read\\_fwf**() – use this for fixed-width formatted files.\n",
    "\n",
    "As you can see, you have tons of built-in ways to acquire data for your\n",
    "analysis. You'll likely not ever need to \"roll your own\" data gathering\n",
    "tools if you can master the relevant libraries. Have fun!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db4331",
   "metadata": {},
   "source": [
    "Dealing with Missing Data And Outliers\n",
    "--------------------------------------\n",
    "\n",
    "In the real world, data sets are often messy. Some of the \"mess\" is due\n",
    "to missing data – a weather instrument may be out of order, a respondent\n",
    "skipped a question, etc. Sometimes it's due to data that's all over the\n",
    "map – due either to real randomness or things like an electrical spike\n",
    "in the weather instrument or a respondent misunderstanding the question.\n",
    "Whatever the cause, it's often necessary to tidy up a data set before\n",
    "analyzing it – and in the process better understand its \"texture and\n",
    "color\".\n",
    "\n",
    "This section will show you some of the ways you can preprocess a raw\n",
    "dataset using native Python tools. In the process, I'll show you some\n",
    "embedded ways to whistle up pandas objects and populate them with data\n",
    "with straight Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5588b78",
   "metadata": {},
   "source": [
    "## A Quick Tip - Start Simple\n",
    "\n",
    "Here's a tip: when exploring new methods or objects in pandas, you may\n",
    "want to start with synthetic and/or well-understood data. \n",
    "\n",
    "We've seen\n",
    "examples of using syntetetic data with playing with the **DataFrame**\n",
    "object – this helps you make sure the operations are working as you\n",
    "intend before using them to explore data sets you don't (yet)\n",
    "understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab50bbec",
   "metadata": {},
   "source": [
    "##  Missing Data\n",
    "\n",
    "Missing data is a fact of life in the real world. It's flagged in\n",
    "various ways. For instance you might find \"NA\", \"n/a\", etc. in text\n",
    "data. Sometimes it will be encoded in agreed-upon values e.g., missing\n",
    "weather data from the NWS often appears as -999. Missing column values\n",
    "from a spreadsheet might appear as NULL. Here are a few ways to handle\n",
    "it in Python.\n",
    "\n",
    "Consider the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6761dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Produce a Series\n",
    "total_observed = 100\n",
    "s = pd.Series(np.random.choice([10, 20, 30, 40, -9], total_observed))\n",
    "\n",
    "# Print some diagnostics\n",
    "print('count: {} missing: {}'.format(s.count(),\n",
    "                                     total_observed-s.count()))\n",
    "\n",
    "# Make a quick and dirty histogram\n",
    "h = s.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e23910",
   "metadata": {},
   "source": [
    "Here, we've created a **Series** object using the **np.random.choice**()\n",
    "method (this wraps the standard Python random library). This will take\n",
    "the values provided in an iterable and produce a **Series** with\n",
    "**total\\_observed** elements, each chosen randomly from iterable's\n",
    "elements. The -9 stands in for an encoded missing value.\n",
    "\n",
    "\n",
    "To get rid of the missing values we can tap the **replace**() method of\n",
    "the **Series** object. It works just like the **str** method. \n",
    "\n",
    "Here, we\n",
    "take advantage that pandas (via NumPy) has a special placeholder for\n",
    "missing data, **np.nan**. This placeholder is cool because it\n",
    "magically drops out of calculations like means, standard deviations, and\n",
    "counts.\n",
    "\n",
    "The optional keyword **inplace** = **True** means a new object\n",
    "will not be created as a result of the operation and that **None** will\n",
    "be returned. \n",
    "\n",
    "Check this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.replace(-9, np.nan, inplace=True)  # <-- inplace=True\n",
    "h = s.hist()\n",
    "\n",
    "print('count: {} missing: {}'.format(s.count(),\n",
    "                                     total_observed-s.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ac7ac",
   "metadata": {},
   "source": [
    "When it's run, the missing values are replaced by the **np.nan** object,\n",
    "rendered as \"NaN\". \n",
    "\n",
    "Note that the **count**() method reflects the length\n",
    "of the **Series** sans the missing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4b3d22",
   "metadata": {},
   "source": [
    "If you want to scrub the NaN values completely, you can use the\n",
    "**dropna**() method. \n",
    "\n",
    "This, too, has an optional **inplace** keyword\n",
    "option. If you choose not to use it, you'll need to use the assignment\n",
    "operator '=' to make the changes \"stick\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69afff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a fresh Series\n",
    "s = pd.Series([10, np.nan, 20, np.nan])\n",
    "\n",
    "print(f\"Original series:\\n\\n{s}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new object\n",
    "new_s = s.dropna()  # no inplace = True\n",
    "\n",
    "# ... or do the inplace operation:\n",
    "s.dropna(inplace=True)\n",
    "\n",
    "print(f\"New series:\\n\\n{s}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f30370c",
   "metadata": {},
   "source": [
    "Note that the output reflects that the index values associated with the\n",
    "missing data have disappeared (the original data is associated with the\n",
    "original indices). The length of the **Series** reflects the removal of\n",
    "the NaNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59debbab",
   "metadata": {},
   "source": [
    "If you simply want to extract null values, you can use use the\n",
    "**isnull**() method\n",
    "\n",
    "If you want the valid values, you can\n",
    "use the **np**.**notnull**() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ff09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a fresh Series\n",
    "s = pd.Series([10, np.nan, 20, np.nan])\n",
    "\n",
    "s.isnull()   # The opposite is notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6931951e",
   "metadata": {},
   "source": [
    "You can use NaN (or any other criteria) to make a mask.   A way to make a series out of the non-null values is to use the results of the null test the same way as a slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "s[s.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326b14a2",
   "metadata": {},
   "source": [
    "## Replacing Missing Values\n",
    "\n",
    "Sometimes you want to replace missing values with reasonable estimates\n",
    "of what the data probably is. For instance, if you are looking at hourly\n",
    "temperatures and have gaps, you have a pretty good idea that the missing\n",
    "values are going to be between the good observations. Pandas has some\n",
    "ways to handle this situation. \n",
    "\n",
    "To illustrate, let's generate a clean\n",
    "**Series** with some NaN values sprinkled in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca404377",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([100, np.nan, np.nan, np.nan, 200])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bbeb51",
   "metadata": {},
   "source": [
    "If we want, we can give the null values a specific new value using\n",
    "**np.fillna**(). \n",
    "\n",
    "We'll make a deep copy of the original and try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aee151",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = s.copy()\n",
    "t = t.fillna(\"Zilch!\")\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2980d9",
   "metadata": {},
   "source": [
    "We can get a little fancier and pick one of the bracketing good values\n",
    "to serve as the new value. \n",
    "\n",
    "The **ffill**() method takes the previous\n",
    "valid data point and projects it \"forward\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5fbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = s.copy()\n",
    "t = t.fillna(method='ffill')\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7837f734",
   "metadata": {},
   "source": [
    "The opposite method, **bfill**() takes the next good value as the\n",
    "replacement. For this example, we'll also use the **limit** keyword\n",
    "argument – this limits the number of consecutive missing values to be\n",
    "replaced (works for **ffill**() as well). \n",
    "\n",
    "You might want to set this to\n",
    "a reasonable number such that really big gaps are apparent when you run\n",
    "quality checks, and that estimated values don't span such large gaps\n",
    "that they become bogus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = s.copy()\n",
    "# <--- gaps larger than 2 are not auto-filled\n",
    "t = t.fillna(method='bfill', limit=2)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf7c693",
   "metadata": {},
   "source": [
    "Often times, you'll want to get a bit fancier and calculate interpolated\n",
    "values. Again pandas comes to the rescue with the cleverly-named\n",
    "**interpolate**() method. \n",
    "\n",
    "Here is its basic usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8b150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = s.copy()\n",
    "t = t.interpolate()\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd926b4",
   "metadata": {},
   "source": [
    "The **interpolate**() method has lots of options. \n",
    "\n",
    "As with **ffill**()\n",
    "and **bfill**() we can tell it whether to project new values forward or\n",
    "backwards, and set a limit as to the number of consecutive null values\n",
    "to be replaced. \n",
    "\n",
    "It also supports different \"flavors\" of interpolation\n",
    "(as you can see from the results, the default is linear) – and that's\n",
    "where the direction of the projection can become material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef5caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.Series([100, 120, np.nan, np.nan, np.nan, 200])\n",
    "\n",
    "t = t.interpolate(method='quadratic', direction='backward')\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b358f207",
   "metadata": {},
   "source": [
    "You'll note that we had to give the **Series** another good value to\n",
    "support the quadratic extrapolation method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30720041",
   "metadata": {},
   "source": [
    "The interpolation options include **cubic**, **polynomial**, **nearest**\n",
    "(picks the most proximate good value), etc. If you want to explore all\n",
    "of the options, you may want check out the docs:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.interpolate.html#pandas.Series.interpolate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa7e6ce",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "Sometimes your data will contain elements that simply cannot be valid.\n",
    "Let's say your relative humidity monitoring equipment suddenly says\n",
    "\"200\" – a physically impossible metric. You would want to throw that\n",
    "data point out before doing any analysis. Or let's say you're measuring\n",
    "outdoor temperatures on a winter day and get sporadic readings in the\n",
    "120 degree (F) range. This is pretty suspect and probably indicates an\n",
    "instrumentation error.\n",
    "\n",
    "Or let's say you're measuring things like rainfall and baseball\n",
    "statistics and learn that in 2016 Houston got 50\" of rain in a week\n",
    "eight months after the Cubs won the World Series. This can't be correct.\n",
    "\n",
    "Ummm. The point is that you should scrub outliers carefully and with\n",
    "plenty of reflective thought. \n",
    "\n",
    "Anyway, here are a couple of ways to\n",
    "handle them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751de3bb",
   "metadata": {},
   "source": [
    "#### Known-Value Outliers\n",
    "\n",
    "In the case that a class of observations is truly impossible, the\n",
    "process is easy – we have lots of good options. \n",
    "\n",
    "Let's say we had\n",
    "relative humidity measures (that's the amount of water vapor contained\n",
    "in the air relative to the maximum amount the air can possibly hold at\n",
    "any given temperature). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0bdde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh = pd.Series([3, 50, -4, 99, 201])\n",
    "rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980a4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it's simple, you can use a 'logical slice' of the original\n",
    "rh[rh > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9cb8c",
   "metadata": {},
   "source": [
    "The syntax gets picky with multiple conditions, but you can provide a range of valid conditions like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb6e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh[(rh >= 0) & (rh <= 100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea9db23",
   "metadata": {},
   "source": [
    "More elegantly, you might try the **mask**() method. \n",
    "\n",
    "This will keep the same shape of the data (won't drop elements) and replace out-of-spec data with NaN.\n",
    "\n",
    "The logic here is \"backward\" from a slice.  We tell mask() affirmatively what to kick out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b1d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "rh.mask((rh < 0) | (rh > 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e305898b",
   "metadata": {},
   "source": [
    "#### Distributional Outliers\n",
    "\n",
    "Sometimes, you'll have a situation where you don't understand the data\n",
    "that well and you identify values that are way out of whack with\n",
    "the rest of them. \n",
    "\n",
    "One systematic way you might do this is **\"z-distribution normalization\"** or more simply \"standardization\".\n",
    "\n",
    "Assuming your data has a normal distribution there are lots of statistical tricks\n",
    "you can use to wrangle it. The normal distribution is really well\n",
    "understood to the point where there are all kinds of inferences you can\n",
    "make around it, and all kinds of methodologies based on its properties.\n",
    "\n",
    "In order to make use of many of the tools and techniques available, you\n",
    "need to make your (probably messy) real world data look like the\n",
    "idealized form. That involves some linear rescaling – this doesn't\n",
    "remove any information content from your data but makes it much more\n",
    "tractable.\n",
    "\n",
    "Essentially you want to rescale your data so that it has a mean of zero\n",
    "and standard deviation of one (that's called a \"standard normal\"\n",
    "distribution)."
   ]
  },
  {
   "attachments": {
    "normal_dist.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "f315200e",
   "metadata": {},
   "source": [
    "In the ideal world it looks like this:\n",
    "\n",
    "![normal_dist.png](attachment:normal_dist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d7ccfc",
   "metadata": {},
   "source": [
    "The mean is the average of the observations – add them up and\n",
    "divide by the count. That's going to be right in the middle of the curve\n",
    "if you plot your observations.\n",
    "\n",
    "The standard deviation is a little more complicated. It's a\n",
    "measure of the \"spread\" of the data. A high standard deviation means a\n",
    "wide distribution. A low standard means a more \"peaked\" one.\n",
    "\n",
    "It's based on something called the variance (actually, the\n",
    "standard deviation is just its square root). \n",
    "\n",
    "To get the variance,\n",
    "you find the difference between each observation and the mean. Then\n",
    "square each difference (this makes sure that each contribution is a\n",
    "positive number that reflects how far off-center the observation is).\n",
    "Then figure out the mean (average) of all the squared differences.\n",
    "\n",
    "In 'mathy' parlance:\n",
    "\n",
    "    Variance = [ SUM (observed - mean ) ^2 ] / number of observations\n",
    "\n",
    "    Standard deviation = SQRT (Variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d334b4f",
   "metadata": {},
   "source": [
    "Back to rescaling ... you want to transform your observations so that it\n",
    "looks as close to the ideal version as possible. \n",
    "\n",
    "To accomplish that you\n",
    "make up a scaling factor based on the mean and standard deviation of the\n",
    "entire data set then apply it to each element.\n",
    "\n",
    "This involves subtracting the mean (that centers the distribution) and\n",
    "dividing by the standard deviation (this controls the \"spread\").\n",
    "\n",
    "Here's a simple example, starting with a weird distribution called the\n",
    "Gumbel distribution.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Gumbel_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc4d56",
   "metadata": {},
   "source": [
    "... which yields this probability density function (PDF). You can see that its \"center of\n",
    "mass\" is right over the zero mark on the x-axis and that the right tail\n",
    "has been pulled in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "bins = 100\n",
    "data = np.random.gumbel(size=2000) * 2 - 4\n",
    "original_ser = pd.Series(data)\n",
    "original_ser.hist(bins=bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ff4c1",
   "metadata": {},
   "source": [
    "As an aside, the np.random library supports dozens of distributrions.\n",
    "\n",
    "The docs provide links to technical descriptions of all of them.   A great weekend read ;-):\n",
    "https://numpy.org/doc/1.16/reference/routines.random.html\n",
    "\n",
    "|\t\t|\t\t|\t\t\t|\n",
    "|-----------------|----------------------|-----------------------|\n",
    "|\t\t|\t\t|\t\t\t|\n",
    "|\tbeta\t|\tlognormal\t|\tstandard_cauchy\t\t|\n",
    "|\tbinomial\t|\tlogseries\t|\tstandard_exponential\t\t|\n",
    "|\tchisquare\t|\tmultinomial\t|\tstandard_gamma\t\t|\n",
    "|\tdirichlet\t|\tmultivariate_normal\t|\tstandard_normal\t\t|\n",
    "|\texponential\t|\tnegative_binomial\t|\tstandard_t\t\t|\n",
    "|\tf\t|\tnoncentral_chisquare\t|\ttriangular\t\t|\n",
    "|\tgamma\t|\tnoncentral_f\t|\tuniform\t\t|\n",
    "|\tgeometric\t|\tnormal\t|\tvonmises\t\t|\n",
    "|\tgumbel\t|\tpareto\t|\twald\t\t|\n",
    "|\thypergeometric\t|\tpoisson\t|\tweibull\t\t|\n",
    "|\tlaplace\t|\tpower\t|\tzipf\t\t|\n",
    "|\tlogistic\t|\trayleigh\t|\t \t\t|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ef2dc9",
   "metadata": {},
   "source": [
    "Back to transforming distributions...\n",
    "\n",
    "Here's how to normalize a distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4473fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean() and std() functions are methods of the Series object\n",
    "mean = original_ser.mean()\n",
    "stdev = original_ser.std()\n",
    "\n",
    "# Center the distribution at 0 (the 't-mean' bit) then denominate by the standard deviation\n",
    "norm = (original_ser - mean) / stdev\n",
    "norm.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95898af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The mean is now {norm.mean():3f} with a StdDev of {norm.std():3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5efd6",
   "metadata": {},
   "source": [
    "\n",
    "One nice thing about this transformed distribution is that we can use\n",
    "the x-axis to determine cutoff points (in terms of the standard\n",
    "deviation) that enclose particular fractions of the distribution. \n",
    "\n",
    "If we\n",
    "look at the idealized distribution above, we can see that the 99% of all\n",
    "observations are within 3 standard deviations of the mean; 95% are\n",
    "within 2 standard deviations; and two-thirds are within one standard\n",
    "deviation.\n",
    "\n",
    "This makes it easy to use a rule-based approach to throwing out\n",
    "potentially-aberrant observations. So, for instance, we might want to\n",
    "get rid of everything that's more than 2 standard deviations from the\n",
    "mean – getting rid of 5% of the data in an ideal world .\n",
    "\n",
    "Here's one way to approach the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.Series([1, 2, 3, 4, 5])\n",
    "\n",
    "# Use a logical test to identify good values, creating a new object.\n",
    "bmask = test[test >= 3]\n",
    "\n",
    "# The index of the new object has valid index points\n",
    "bmask.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa56f42",
   "metadata": {},
   "source": [
    "We can \"borrow\" the new object's index and use it to select elements of the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[bmask.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b287a26e",
   "metadata": {},
   "source": [
    "This example is a bit silly because the solution is obvious, but it's a general technique that can come in handy:\n",
    "\n",
    "- do any number of transformations on original data\n",
    "\n",
    "\n",
    "- create a mask against the transformed version\n",
    "\n",
    "\n",
    "- apply the mask back to the original data\n",
    "\n",
    "Now, let's chop off any data that's more than two standard deviations from the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find values mean +/- 2 standard deviations\n",
    "bmask = norm[(norm > -2) & (norm < 2)]\n",
    "clean = norm[bmask.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd61b86",
   "metadata": {},
   "source": [
    "Here, we'll do a quick-and-dirty plot to check out our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2cdd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_title(\"original\")\n",
    "original_ser.hist(bins=bins, ax=ax)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(\"normalized\")\n",
    "norm.hist(bins=bins, ax=ax)\n",
    "\n",
    "ax = axes[2]\n",
    "ax.set_title(\"clean\")\n",
    "clean.hist(bins=bins, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd2a761",
   "metadata": {},
   "source": [
    "We can apply the same index against the original values. The visual\n",
    "effect is less dramatic, but we've chopped off the highest values so\n",
    "instead of the x-axis going to around 7 it now stops at about 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9e28c3",
   "metadata": {},
   "source": [
    "These are just a couple fairly straightforward data cleaning methods.\n",
    "Naturally, things can get more complicated. \n",
    "\n",
    "For instance, if you're\n",
    "interested in filtering signals (noise reduction, etc.) you might check\n",
    "out the **signal** library at:\n",
    "\n",
    "https://docs.scipy.org/doc/scipy-0.18.1/reference/signal.html. \n",
    "\n",
    "If you're interested in image processing\n",
    "(cancelling out \"green screen\" effects, etc.) you might investigate:\n",
    "\n",
    "    - pillow/PIL https://python-pillow.org/\n",
    "    \n",
    "    - ndimagey https://docs.scipy.org/doc/scipy/reference/ndimage.html\\#module-scipy.ndimage\n",
    "    \n",
    "    - scikit-image https://scikit-image.org. \n",
    "\n",
    "Unfortunately, these are beyond the scope of the\n",
    "present class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5150512",
   "metadata": {},
   "source": [
    "Slicing, Dicing and Re-indexing\n",
    "-------------------------------\n",
    "\n",
    "As you've seen already, NumPy and pandas objects work a lot like\n",
    "**list** objects. They carry indices along with them and can be\n",
    "addressed via slicing operations. \n",
    "\n",
    "They also work a lot like **dict**\n",
    "objects where values/components can be addressed by named key values.\n",
    "You've also seen that these objects have separate index and value\n",
    "components and that the index can be \"borrowed\" from one object and\n",
    "applied to another. \n",
    "\n",
    "This section will take a further look at how all\n",
    "this works and how you can apply it to your advantage. \n",
    "\n",
    "For simplicity of\n",
    "exposition we'll focus on the **Series** object, but the concepts are\n",
    "easily applied to other objects like the **DataFrame** and **Panel** –\n",
    "and most to NumPy **ndarrays** upon which these are built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6552b",
   "metadata": {},
   "source": [
    "### Index Objects\n",
    "\n",
    "Unlike a **list** object, pandas index objects are largely under the\n",
    "control of the user. This is evident as we apply the **Series** object's\n",
    "constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd3847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_index = [\"duck0\", \"duck5\", \"duck10\"]\n",
    "data = (0, 5, 10)\n",
    "s = pd.Series(data=data, index=duck_index)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4258f",
   "metadata": {},
   "source": [
    "We can play around with this, accessing elements in a variety of ways as\n",
    "we get our ducks in a row : -)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c4e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"duck0\":\"duck5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161cc652",
   "metadata": {},
   "source": [
    "Note: the Pandas' name-based slicing works a bit differently than index-based slicing.  With name-based slices, the operation returns an object **inclusive** of the last element.   You can see we got \"duck5\" as the last element.\n",
    "\n",
    "Slicing a list, like duck_index excludes the last element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6862c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlist = duck_index\n",
    "dlist[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4f8a9b",
   "metadata": {},
   "source": [
    "The indices and values are essentially stored separately, and can be\n",
    "addressed accordingly.   Pandas lets us \"bolt on\" additional indices.\n",
    "\n",
    "Note from the output below that the **Index** is\n",
    "a different object than the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7217e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853cdae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae347250",
   "metadata": {},
   "source": [
    "We can, if we want create a new **Index** object from its constructor\n",
    "and apply it to our array. \n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d13cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quacker_index = pd.Index(['qucker1', 'quacker2', 'quacker3'], dtype='object')\n",
    "s.index = quacker_index\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb95dae",
   "metadata": {},
   "source": [
    "### Re-Indexing\n",
    "\n",
    "The fact that the index and values are separate is really powerful\n",
    "because it allows rearranging data along new indices as they are\n",
    "provided. \n",
    "\n",
    "Consider this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99f5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index = duck_index\n",
    "print(f\"Ducks:\\n\\n{s}\\n\")\n",
    "\n",
    "newix = [\"duck0\", \"duck1\", \"duck2\", \"duck5\", \"duck10\"]\n",
    "s = s.reindex(newix)\n",
    "print(f\"Reindexed: \\n\\n{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01389ed3",
   "metadata": {},
   "source": [
    "By inspection, you can observe that the existing values associated with\n",
    "the original indices for \"duck0, duck5, and duck10\" all persisted.\n",
    "\n",
    "\n",
    "Placeholders were created for the newly-added index points. We didn't\n",
    "even have to create a separate **Index** object – pandas was smart\n",
    "enough to know we needed one (it'll actually work with anything that\n",
    "looks like it will fit – a **tuple**, **array**, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8170cd9e",
   "metadata": {},
   "source": [
    "\n",
    "If we want, we can ask to fill in the placeholders as the index is\n",
    "expanded using the methods **bfill**(), **ffill**(), and **nearest**().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da4d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34f3bd4",
   "metadata": {},
   "source": [
    "It's also possible to sort a **Series** using by **sort\\_index**() and\n",
    "**sort\\_values**(). \n",
    "\n",
    "Be careful, though, as the results may not be what\n",
    "you expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb3e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3458c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c47076",
   "metadata": {},
   "source": [
    "Data Description / Analysis Tools\n",
    "---------------------------------\n",
    "\n",
    "Pandas has a pretty good set of data introspection tools baked right\n",
    "into the objects. We'll go over these in more detail as we analyze real\n",
    "data, but here's an overview.\n",
    "\n",
    "Working still with the Gumbel distribution, we'll make a two-column\n",
    "**DataFrame** object by providing a **dict** to the constructor:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce6e2a4",
   "metadata": {},
   "source": [
    "It's possible to use the **DataFrame**'s built-in **describe**() method\n",
    "to get some basic statistics (these will also work on the **Series**\n",
    "object):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa65bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = np.random.gumbel(size=1000)\n",
    "df = pd.DataFrame({'a': data, 'b': data*2})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e058c5f0",
   "metadata": {},
   "source": [
    "The **describe**() method works like most of the others. It actually\n",
    "returns a new **ndarray** object that we can selectively query. \n",
    "\n",
    "Typically, all the Pandas methods return either a pandas.Series or a pandas.DataFrame object.   The most notable exception is when a single value is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8f811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = df.describe()\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dbad68",
   "metadata": {},
   "source": [
    "For\n",
    "instance, if we just wanted the mean from the first column we could go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944666b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['a']['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242a11b0",
   "metadata": {},
   "source": [
    "We can, alternatively, directly query this information using methods\n",
    "like **mean**(), **min**(), **std**(), **kurtosis**(), and **max**().\n",
    "\n",
    "Here are a few examples. Note that you have a choice of syntax when\n",
    "accessing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce04db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf63123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb71f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d67a7d9",
   "metadata": {},
   "source": [
    "We can whistle up some tests quickly. \n",
    "\n",
    "Here's a test for normality run\n",
    "against the first column of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9657fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = stats.normaltest(df['a'])\n",
    "print(sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35450810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For most of these tests, we can run them like this:\n",
    "test_stat, pvalue = stats.normaltest(df['a'])\n",
    "\n",
    "print(f\"The test of normalicy has a p-value of {pvalue:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603ea32a",
   "metadata": {},
   "source": [
    "We can go ahead and pick off the components. \n",
    "\n",
    "The 'statistic' is the\n",
    "combined z-score for tests of skewness and kurtosis. That's very roughly\n",
    "the number of standard deviations away from what we'd expect if the\n",
    "distribution was perfectly normal – a small number is better than a\n",
    "larger one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eebbc0",
   "metadata": {},
   "source": [
    "The **'pvalue'** is what we're really after. \n",
    "\n",
    "The **pvalue** provides an\n",
    "estimate of how much confidence we can have about rejecting the null\n",
    "hypothesis (that the distribution is normal). \n",
    "\n",
    "In this case the null\n",
    "hypothesis is that the distribution is normal and smaller the p-value,\n",
    "the more certain we are that the distribution doesn't fit the normal\n",
    "distribution. \n",
    "\n",
    "At p=.05, we'd be 95% certain that we can reject..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6fa82",
   "metadata": {},
   "source": [
    "... and with a value this low there's about zero percent chance that\n",
    "we've made a bad call. Another way to get at the same question is to ask\n",
    "whether, based on the skewness of our data, whether it probably came\n",
    "from a normally-distributed population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469b339d",
   "metadata": {},
   "source": [
    "Some of the other tests available include **binom\\_test** (tests if\n",
    "binomally distributed) and **ttest\\_ind** (tests two samples to figure\n",
    "out whether they probably came from the same population by comparing\n",
    "their means).\n",
    "\n",
    "Here is how to use **ttest\\_ind**(). It takes two array-like objects and\n",
    "is pretty flexible in just what they are – **ndarrays**, **Series**, and\n",
    "even humble **list** objects all work equally well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8412c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat, pvalue = stats.ttest_ind(df['a'], df['b'])\n",
    "print(f\"The t-test for independent means yields a p-value of {pvalue:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2af4c",
   "metadata": {},
   "source": [
    "But we should really not be cavalier about this.   Nothing about Python's data science stack is 'hand-holdy'.   Sure, we've got a result, but is it any good?   Is it garbage?   To Python, we've handed off a couple of arrays and it handed off some numbers.\n",
    "\n",
    "Unless you KNOW what a t-test for independent means is, and a lot of other things about it, you don't want to share your results or any conclusions you draw.\n",
    "\n",
    "Here, you might google something like \"t-test for independent means assumptions\".   You then may discover a web site like:\n",
    "\n",
    "http://www.psychology.emory.edu/clinical/bliwise/Tutorials/TOM/meanstests/tind.htm\n",
    "\n",
    "There you might learn that:\n",
    "\n",
    "    - the null hypothesis is that populations means are equal\n",
    "    \n",
    "    - we assume that the sample means provide a reliable estimate of the population mean\n",
    "    \n",
    "    - we assume that the data represent interval or ratio scales\n",
    "    \n",
    "    - the populations are normally distributed\n",
    "    \n",
    "    - the populations have the same variance\n",
    "         \n",
    "    - the test assumes no overlap between the two groups these data represent\n",
    "    \n",
    "Digging deeper, you might discover that you can check variances with a Levene test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat, pvalue = stats.levene(df['a'], df['b'])\n",
    "print(f\"The Levene test for equal variances yields a p-value of {pvalue:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f689c1d",
   "metadata": {},
   "source": [
    "You get the idea.  The stats tests are a chainsaw in that they need to be used with care and respect.\n",
    "\n",
    "Back to our example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f39da0",
   "metadata": {},
   "source": [
    "One can just \"eyeball\" this result to see that that the two columns of\n",
    "our **DataFrame** are not from the same population.\n",
    "\n",
    "The docstring will get you the gory details on how to compare\n",
    "the means of two related samples. It'll show you how to manage treatment\n",
    "of missing values, etc.   \n",
    "\n",
    "That being said, the docstring will generally tell you more about the implementaton of a test than it will about the theory behind it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be9757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(stats.ttest_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fb3004",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "rotowire.com publishes an excellent compendium of baseball statistics. Some of these are available in your course materials file directory as \"baseball_stats.xls\".   http://www.rotowire.com/baseball/player_ex_stats\n",
    "\n",
    "Please practice some of your chops against this file.\n",
    "\n",
    "- use the pandas read_excel() method to read columns \"A\" to \"M\" only.\n",
    "\n",
    "\n",
    "- one of the columns, \"bb_pct\" shows the percentage of at-bats that resulted in walks. Create a histogram so you can examine it.\n",
    "\n",
    "\n",
    "- find the mean and standard deviation then determine if this is probably normally distributed.\n",
    "\n",
    "\n",
    "- prune the outliers (maybe get rid of zero values and those above 20%).\n",
    "\n",
    "\n",
    "- create a standardized version of the pruned distribution then trim it so it contains only the data that's within one standard deviation of the mean. Use its index to create a pruned version of the original.\n",
    "\n",
    "\n",
    "\n",
    "How does the mean and standard deviation of the this version compare to the original? Is it more or less likely to be normally-distributed?\n",
    "\n",
    "Extra credit:\n",
    "\n",
    "Create a bunch of new Series, based on subsets of the pruned version, with varying numbers of observations and determine whether each is likely to be normally-distributed (you need at least 20 for normaltest() to work, and should get at least 100 at the high end). You can use slice notation or perhaps the sample() method of the Series object here. Gather the results into a new Series and create a histogram.\n",
    "\n",
    "What do you observe about the p-value as the number of observations grows?\n",
    "\n",
    "\n",
    "\n",
    "Solution:  solution_baseball_hitting.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": "15",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "353.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
